{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db474ea",
   "metadata": {},
   "source": [
    "# persistent in langgraph\n",
    "Persistence in LangGraph means saving the memory and state of your AI workflow (graph) so it doesnâ€™t get lost when something goes wrong or when you want to resume later.\n",
    "\n",
    "Think of it like a save game feature in a video game.\n",
    "\n",
    "- Without persistence â†’ if the game crashes, you lose progress.\n",
    "\n",
    "- With persistence â†’ you reload from the last checkpoint.\n",
    "\n",
    "So in LangGraph, persistence allows your workflow to survive crashes, restarts, or interruptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6788c2",
   "metadata": {},
   "source": [
    "# Fault tolerance\n",
    "Fault tolerance means the system can recover from errors without starting everything from scratch.\n",
    "\n",
    "Persistence helps by:\n",
    "\n",
    "- Saving progress at certain steps (checkpoints).\n",
    "\n",
    "- If an error or crash happens, the graph reloads from the last checkpoint instead of starting at the beginning.\n",
    "\n",
    "- This makes the system more reliable and faster because you donâ€™t redo completed steps.\n",
    "\n",
    "ğŸ”¹ Example:\n",
    "Imagine you are building a workflow that processes a customerâ€™s request in 5 steps:\n",
    "\n",
    "- Validate user input\n",
    "\n",
    "- Retrieve information from a database\n",
    "\n",
    "- Summarize the data\n",
    "\n",
    "- Generate a response\n",
    "\n",
    "- Send it back to the user\n",
    "\n",
    "If the system crashes at step 4:\n",
    "\n",
    "- Without persistence â†’ you must start again from step 1.\n",
    "\n",
    "- With persistence â†’ you restart from step 3 or 4 (where you last saved).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97255bfe",
   "metadata": {},
   "source": [
    "# checkpointers in persistent\n",
    "Checkpointers are like â€œsave pointsâ€ in a workflow.\n",
    "\n",
    "- They store the state (data, inputs, outputs) of the workflow at specific moments.\n",
    "\n",
    "- Later, you can reload the workflow from that checkpoint.\n",
    "\n",
    "ğŸ”¹ Example:\n",
    "Think of an online exam system:\n",
    "\n",
    "- Every 5 minutes, it autosaves your answers (checkpoints).\n",
    "\n",
    "- If your laptop shuts down, when you log back in, your answers up to the last save are still there.\n",
    "\n",
    "In LangGraph, checkpointers do the same thing for AI workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bfcc4",
   "metadata": {},
   "source": [
    "# Threads in persistent\n",
    "\n",
    "A thread is like a separate conversation or workflow instance that gets its own saved state.\n",
    "\n",
    "- Each thread has its own memory and checkpoints.\n",
    "\n",
    "- You can pause one thread and start another, then come back later.\n",
    "\n",
    "ğŸ”¹ Example:\n",
    "Think of WhatsApp chats:\n",
    "\n",
    "- Each chat with a person is like a â€œthread.â€\n",
    "\n",
    "- Messages are saved (persistent), so when you reopen the chat, you see the history.\n",
    "\n",
    "- Each conversation is independent of the others.\n",
    "\n",
    "In LangGraph, threads let you manage multiple workflows (conversations, tasks, or jobs) at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0df825",
   "metadata": {},
   "source": [
    "# benefits of Persistent\n",
    "- Short term Memory\n",
    "- Fault Tolerance\n",
    "- Human in the loop\n",
    "- Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2701b9a",
   "metadata": {},
   "source": [
    "# MemorySaver vs InMemorySaver\n",
    "- InMemorySaver â†’ Very simple saver, keeps checkpoints only in RAM, lost when program ends. Good for quick testing.\n",
    "\n",
    "- MemorySaver â†’ Higher-level saver that organizes checkpoints per thread for LangGraph workflows. Still in-memory, but structured for persistence during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0153f807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from typing import  Annotated,TypedDict\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6ea1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class state(TypedDict):\n",
    "    topic:str\n",
    "    joke:str\n",
    "    explain:str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ad87ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model='llama-3.1-8b-instant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dc63344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_gen(state:state):\n",
    "    prompt=f\"Generate the short joke on the foolowing topic :{state['topic']}\"\n",
    "    response=llm.invoke(prompt)\n",
    "    return {'joke':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2eadf032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_exp(state:state):\n",
    "    prompt=f\"explain the following joke in urdu {state['topic']}\"\n",
    "    exp=llm.invoke(prompt)\n",
    "    return {'explain':exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49276690",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(state)\n",
    "graph.add_node('joke_gen',joke_gen)\n",
    "graph.add_node('joke_exp',joke_exp)\n",
    "\n",
    "graph.add_edge(START,'joke_gen')\n",
    "graph.add_edge('joke_gen','joke_exp')\n",
    "graph.add_edge('joke_exp',END)\n",
    "\n",
    "checkpointer=InMemorySaver()\n",
    "chatbot=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ca10aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae1e86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'configurable':{'thread_id':thread_id}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'pizza'},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce0dca8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016608481, 'prompt_time': 0.005815748, 'queue_time': 0.090975112, 'total_time': 0.022424229}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9a162ff8-f8c6-432b-a42e-74563bee7c01-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}),\n",
       " 'explain': AIMessage(content='ÛŒÛ Ø¬Ù…Ù„Û Ø§ÛŒÚ© Ø¬ÙˆÚ© ÛÛ’ Ø¬Ø³ Ù…ÛŒÚº Ø§ÛŒÚ© Ø´Ø®Øµ Ù†Û’ Ø§ÛŒÚ© Ù¾ÛŒØªØ²Ø§ Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº Ú©ÛØ§ ÛÛ’Û”\\n\\n\"Ù¾ÛŒØªØ²Ø§\"\\n\\nØ§Ø³ Ø¬Ù…Ù„Û’ Ú©Ø§ Ù…Ø·Ù„Ø¨ ÛÛ’ \"Ù¾ÛŒØªØ²Ø§\" ÛÛŒ Ø¬Ø³ Ú©Ø§ Ø­ÙˆØ§Ù„Û Ø¯ÛŒØªØ§ ÛÛ’Û” ÛŒÛ Ø§ÛŒÚ© Ø§ÛŒØ³ÛŒ Ø¨Ø§Øª ÛÛ’ Ø¬Ùˆ ØµØ±Ù \"Ù¾ÛŒØªØ²Ø§\" Ú©Ø§ Ø°Ú©Ø± Ú©Ø±ØªÛŒ ÛÛ’ØŒ Ø¬ÛŒØ³Û’ Ú©Û Ø§ÛŒÚ© Ø´Ø®Øµ Ú©Û’ Ø¨Ú¾Ø§Ú¯ Ø¬Ø§Ù†Û’ Ú©ÛŒ ÙˆØ¬Û \"Ù¾ÛŒØªØ²Ø§\" ÛÙˆÛ”\\n\\nÛŒÛ Ø¬ÙˆÚ© Ø§Ø³ Ø¨Ø§Øª Ù¾Ø± Ù…Ø¨Ù†ÛŒ ÛÛ’ Ú©Û Ù¾ÛŒØªØ²Ø§ Ø§ÛŒÚ© Ø§ÛŒØ³Ø§ Ú©Ú¾Ø§Ù†Ø§ ÛÛ’ Ø¬Ø³ Ú©Ø§ Ø°Ú©Ø± Ú©Ø±Ù†Ø§ Ø¨ÛØª Ø¢Ø³Ø§Ù† ÛÛ’ØŒ Ù„ÛŒÚ©Ù† Ø¬Ø¨ Ú©ÙˆØ¦ÛŒ Ø´Ø®Øµ Ú©ÛØªØ§ ÛÛ’ \"Ù¾ÛŒØªØ²Ø§\" ØªÙˆ ÛÙ… Ø³Ù…Ø¬Ú¾ØªÛ’ ÛÛŒÚº Ú©Û ÙˆÛ Ú©Ú†Ú¾ Ø§ÙˆØ± Ø¨Ú¾ÛŒ Ú©ÛÙ†Ø§ Ú†Ø§ÛØªØ§ ÛÛ’Û”', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 287, 'prompt_tokens': 43, 'total_tokens': 330, 'completion_time': 0.4217494, 'prompt_time': 0.015746508, 'queue_time': 0.093942462, 'total_time': 0.437495908}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--fea89cb4-9b54-4245-9875-902dc65282b9-0', usage_metadata={'input_tokens': 43, 'output_tokens': 287, 'total_tokens': 330})}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74008b2a",
   "metadata": {},
   "source": [
    "# Fault tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e644306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_gen1(state:state):\n",
    "    prompt=f\"Generate the short joke on the foolowing topic :{state['topic']}\"\n",
    "    response=llm.invoke(prompt)\n",
    "    print('Generation completed...')\n",
    "    return {'joke':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7f8e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # let llm take time to resposne so we can interrupt our  system for trying fault tolerance\n",
    "def joke_exp1(state:state):\n",
    "    prompt=f\"explain the following joke in urdu {state['topic']}\"\n",
    "    time.sleep(10)\n",
    "    exp=llm.invoke(prompt)\n",
    "    print('Explanation completed...')\n",
    "\n",
    "    return {'explain':exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c0f6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(state)\n",
    "graph.add_node('joke_gen1',joke_gen1)\n",
    "graph.add_node('joke_exp1',joke_exp1)\n",
    "\n",
    "graph.add_edge(START,'joke_gen1')\n",
    "graph.add_edge('joke_gen1','joke_exp1')\n",
    "graph.add_edge('joke_exp1',END)\n",
    "\n",
    "checkpointer=InMemorySaver()\n",
    "chatbot=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d257f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id_n='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4d51ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation completed...\n",
      "Explanation completed...\n"
     ]
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'pizza'},\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "791f5d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}),\n",
       " 'explain': AIMessage(content='ÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’:\\n\\nÙ¾ÛŒØ²Ø§\\n\\nØ§Ù† Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª ÛŒÛ ÛÛ’:\\n\\nØ§ÛŒÚ© Ø´Ø®Øµ Ù†Û’ Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ú©Ùˆ Ù¾ÛÙ†Ú†Ø§ÛŒØ§ Ø§ÙˆØ± Ú©ÛØ§ØŒ \"Ø¢Ø¬ ØªÙˆ Ù…ÛŒØ±Û’ Ù„ÛŒÛ’ ÛÛŒ Ù¾ÛŒØ²Ø§ Ù„Ø§Ø¦ÛŒ ÛÙˆÚºØŒ Ù„ÛŒÚ©Ù† Ù…ÛŒÚº Ù†Û’ Ø³ÙˆÚ†Ø§ ÛÛ’ Ú©Û ØªÙˆ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛÛ’ ÛÙˆ Ú¯Ø§Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ù¾ÙˆÚ†Ú¾Ø§ØŒ \"Ú©ÛŒØ§ ØªÙˆ ÛÛ’ØŸ Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ù¾ÛÙ„Û’ ÛÛŒ Ú©ÛØ§ ØªÚ¾Ø§ Ú©Û Ù…Ø¬Ú¾Û’ Ù¾ÛŒØ²Ø§ Ù†ÛÛŒÚº Ú©Ú¾Ø§Ù†Û’ Ø¯Û’Û”\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§ÛŒØ³Ø§ ÛÛŒ ØªÙˆ Ù†ÛÛŒÚºØŒ ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù…ÛŒÚº Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛØªØ§ ÛÙˆÚºÛ”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛŒØ§ Ú©ÛØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ Ù…ÛŒÚº Ù†Û’ Ú©Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø§Ø¹Ù„Ø§Ù† Ù†ÛÛŒÚº Ú©ÛŒØ§ ØªÚ¾Ø§Û” Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¨Ø¹Ø¯ØŒ Ù¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ú©ÛŒØ§ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ù†ÛÛŒÚº Ø¯ÛŒØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø¬ÛŒ ÛØ§Úº ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’ØŒ Ù¾ÛŒØ²Ø§Û”\"\\n\\nÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’ Ú©Û Ø¬Ø¨ Ø¯ÙˆØ³Ø±Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ Ú©Û \"Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’\" ØªÙˆ Ø§Ø³ Ú©Û’ Ù…Ø¹Ù†ÛŒ Ù…ÛŒÚº \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù…\" Ú©ÛÛ’ Ú¯Ø¦Û’Û”', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ff617da",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    None,\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f45a4737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='ÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’:\\n\\nÙ¾ÛŒØ²Ø§\\n\\nØ§Ù† Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª ÛŒÛ ÛÛ’:\\n\\nØ§ÛŒÚ© Ø´Ø®Øµ Ù†Û’ Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ú©Ùˆ Ù¾ÛÙ†Ú†Ø§ÛŒØ§ Ø§ÙˆØ± Ú©ÛØ§ØŒ \"Ø¢Ø¬ ØªÙˆ Ù…ÛŒØ±Û’ Ù„ÛŒÛ’ ÛÛŒ Ù¾ÛŒØ²Ø§ Ù„Ø§Ø¦ÛŒ ÛÙˆÚºØŒ Ù„ÛŒÚ©Ù† Ù…ÛŒÚº Ù†Û’ Ø³ÙˆÚ†Ø§ ÛÛ’ Ú©Û ØªÙˆ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛÛ’ ÛÙˆ Ú¯Ø§Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ù¾ÙˆÚ†Ú¾Ø§ØŒ \"Ú©ÛŒØ§ ØªÙˆ ÛÛ’ØŸ Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ù¾ÛÙ„Û’ ÛÛŒ Ú©ÛØ§ ØªÚ¾Ø§ Ú©Û Ù…Ø¬Ú¾Û’ Ù¾ÛŒØ²Ø§ Ù†ÛÛŒÚº Ú©Ú¾Ø§Ù†Û’ Ø¯Û’Û”\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§ÛŒØ³Ø§ ÛÛŒ ØªÙˆ Ù†ÛÛŒÚºØŒ ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù…ÛŒÚº Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛØªØ§ ÛÙˆÚºÛ”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛŒØ§ Ú©ÛØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ Ù…ÛŒÚº Ù†Û’ Ú©Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø§Ø¹Ù„Ø§Ù† Ù†ÛÛŒÚº Ú©ÛŒØ§ ØªÚ¾Ø§Û” Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¨Ø¹Ø¯ØŒ Ù¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ú©ÛŒØ§ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ù†ÛÛŒÚº Ø¯ÛŒØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø¬ÛŒ ÛØ§Úº ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’ØŒ Ù¾ÛŒØ²Ø§Û”\"\\n\\nÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’ Ú©Û Ø¬Ø¨ Ø¯ÙˆØ³Ø±Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ Ú©Û \"Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’\" ØªÙˆ Ø§Ø³ Ú©Û’ Ù…Ø¹Ù†ÛŒ Ù…ÛŒÚº \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù…\" Ú©ÛÛ’ Ú¯Ø¦Û’Û”', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c36b-6eda-8002-6c91add157e9'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T20:24:00.216627+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4e3e-6a5a-8001-2547abe51d3c'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4e3e-6a5a-8001-2547abe51d3c'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T20:23:47.929740+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a3a-6738-8000-def77a234269'}}, tasks=(PregelTask(id='6e8d07df-662b-c158-c14e-c2373b21ec3e', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='ÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’:\\n\\nÙ¾ÛŒØ²Ø§\\n\\nØ§Ù† Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª ÛŒÛ ÛÛ’:\\n\\nØ§ÛŒÚ© Ø´Ø®Øµ Ù†Û’ Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ú©Ùˆ Ù¾ÛÙ†Ú†Ø§ÛŒØ§ Ø§ÙˆØ± Ú©ÛØ§ØŒ \"Ø¢Ø¬ ØªÙˆ Ù…ÛŒØ±Û’ Ù„ÛŒÛ’ ÛÛŒ Ù¾ÛŒØ²Ø§ Ù„Ø§Ø¦ÛŒ ÛÙˆÚºØŒ Ù„ÛŒÚ©Ù† Ù…ÛŒÚº Ù†Û’ Ø³ÙˆÚ†Ø§ ÛÛ’ Ú©Û ØªÙˆ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛÛ’ ÛÙˆ Ú¯Ø§Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ù¾ÙˆÚ†Ú¾Ø§ØŒ \"Ú©ÛŒØ§ ØªÙˆ ÛÛ’ØŸ Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ù¾ÛÙ„Û’ ÛÛŒ Ú©ÛØ§ ØªÚ¾Ø§ Ú©Û Ù…Ø¬Ú¾Û’ Ù¾ÛŒØ²Ø§ Ù†ÛÛŒÚº Ú©Ú¾Ø§Ù†Û’ Ø¯Û’Û”\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§ÛŒØ³Ø§ ÛÛŒ ØªÙˆ Ù†ÛÛŒÚºØŒ ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù…ÛŒÚº Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛØªØ§ ÛÙˆÚºÛ”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛŒØ§ Ú©ÛØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ Ù…ÛŒÚº Ù†Û’ Ú©Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø§Ø¹Ù„Ø§Ù† Ù†ÛÛŒÚº Ú©ÛŒØ§ ØªÚ¾Ø§Û” Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¨Ø¹Ø¯ØŒ Ù¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ú©ÛŒØ§ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ù†ÛÛŒÚº Ø¯ÛŒØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø¬ÛŒ ÛØ§Úº ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’ØŒ Ù¾ÛŒØ²Ø§Û”\"\\n\\nÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’ Ú©Û Ø¬Ø¨ Ø¯ÙˆØ³Ø±Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ Ú©Û \"Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’\" ØªÙˆ Ø§Ø³ Ú©Û’ Ù…Ø¹Ù†ÛŒ Ù…ÛŒÚº \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù…\" Ú©ÛÛ’ Ú¯Ø¦Û’Û”', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a3a-6738-8000-def77a234269'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:23:47.508602+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a38-66e1-bfff-11cf76741ec8'}}, tasks=(PregelTask(id='8aaa9cd6-4e7c-0ddc-9aad-8cae1b53133f', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a38-66e1-bfff-11cf76741ec8'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T20:23:47.507781+00:00', parent_config=None, tasks=(PregelTask(id='bf4660b1-f56b-cc2f-622e-b1022a55a932', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chatbot.get_state_history(config=config2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7274c95d",
   "metadata": {},
   "source": [
    "# Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62e883f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation completed...\n",
      "Explanation completed...\n"
     ]
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'burger'},\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93a061ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why was the burger in a bad mood? \\n\\nBecause it had a beef with everything.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 46, 'total_tokens': 65, 'completion_time': 0.027816835, 'prompt_time': 0.093438171, 'queue_time': 0.249228309, 'total_time': 0.121255006}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--059d69f8-5cf2-4344-a35a-ab8b79d87772-0', usage_metadata={'input_tokens': 46, 'output_tokens': 19, 'total_tokens': 65}), 'explain': AIMessage(content='Kuchh zameen se zyada nahin hai, lekin burger nahin bhi hai. (Kuchh zameen se zyada nahin hai) ishara hai kisi cheez ki, aur (burger nahin bhi hai) ishara hai kisi cheez ki jise burger kehte hain, lekin yeh kuchh zameen se zyada nahin hai. \\n\\nIs joke ki maanani, yeh ek burger hai jo kisi zameen se adhik nahin hai, magar yeh burger hai jisne ek zameen se adhik zameen ko apne pass kar liya hai, aur yeh zameen uske pas hai, lekin yeh burger wahi hai, jo kisi zameen se adhik nahin hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 183, 'prompt_tokens': 43, 'total_tokens': 226, 'completion_time': 0.360558966, 'prompt_time': 0.05391899, 'queue_time': 0.104946539, 'total_time': 0.414477956}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d0c8d0a1-db07-428b-8974-6c71c0f0d479-0', usage_metadata={'input_tokens': 43, 'output_tokens': 183, 'total_tokens': 226})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f7-3162-6742-8006-5e849cffb5c2'}}, metadata={'source': 'loop', 'step': 6, 'parents': {}}, created_at='2025-09-06T20:24:11.747080+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c8ec-6402-8005-7826ae8c8d00'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why was the burger in a bad mood? \\n\\nBecause it had a beef with everything.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 46, 'total_tokens': 65, 'completion_time': 0.027816835, 'prompt_time': 0.093438171, 'queue_time': 0.249228309, 'total_time': 0.121255006}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--059d69f8-5cf2-4344-a35a-ab8b79d87772-0', usage_metadata={'input_tokens': 46, 'output_tokens': 19, 'total_tokens': 65}), 'explain': AIMessage(content='ÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’:\\n\\nÙ¾ÛŒØ²Ø§\\n\\nØ§Ù† Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª ÛŒÛ ÛÛ’:\\n\\nØ§ÛŒÚ© Ø´Ø®Øµ Ù†Û’ Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ú©Ùˆ Ù¾ÛÙ†Ú†Ø§ÛŒØ§ Ø§ÙˆØ± Ú©ÛØ§ØŒ \"Ø¢Ø¬ ØªÙˆ Ù…ÛŒØ±Û’ Ù„ÛŒÛ’ ÛÛŒ Ù¾ÛŒØ²Ø§ Ù„Ø§Ø¦ÛŒ ÛÙˆÚºØŒ Ù„ÛŒÚ©Ù† Ù…ÛŒÚº Ù†Û’ Ø³ÙˆÚ†Ø§ ÛÛ’ Ú©Û ØªÙˆ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛÛ’ ÛÙˆ Ú¯Ø§Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ù¾ÙˆÚ†Ú¾Ø§ØŒ \"Ú©ÛŒØ§ ØªÙˆ ÛÛ’ØŸ Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ù¾ÛÙ„Û’ ÛÛŒ Ú©ÛØ§ ØªÚ¾Ø§ Ú©Û Ù…Ø¬Ú¾Û’ Ù¾ÛŒØ²Ø§ Ù†ÛÛŒÚº Ú©Ú¾Ø§Ù†Û’ Ø¯Û’Û”\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§ÛŒØ³Ø§ ÛÛŒ ØªÙˆ Ù†ÛÛŒÚºØŒ ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù…ÛŒÚº Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛØªØ§ ÛÙˆÚºÛ”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛŒØ§ Ú©ÛØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ Ù…ÛŒÚº Ù†Û’ Ú©Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø§Ø¹Ù„Ø§Ù† Ù†ÛÛŒÚº Ú©ÛŒØ§ ØªÚ¾Ø§Û” Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¨Ø¹Ø¯ØŒ Ù¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ú©ÛŒØ§ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ù†ÛÛŒÚº Ø¯ÛŒØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø¬ÛŒ ÛØ§Úº ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’ØŒ Ù¾ÛŒØ²Ø§Û”\"\\n\\nÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’ Ú©Û Ø¬Ø¨ Ø¯ÙˆØ³Ø±Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ Ú©Û \"Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’\" ØªÙˆ Ø§Ø³ Ú©Û’ Ù…Ø¹Ù†ÛŒ Ù…ÛŒÚº \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù…\" Ú©ÛÛ’ Ú¯Ø¦Û’Û”', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c8ec-6402-8005-7826ae8c8d00'}}, metadata={'source': 'loop', 'step': 5, 'parents': {}}, created_at='2025-09-06T20:24:00.793475+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c3af-62b1-8004-a8dc12753a75'}}, tasks=(PregelTask(id='60620d32-202a-70bd-8985-ed1a8bb4725a', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Kuchh zameen se zyada nahin hai, lekin burger nahin bhi hai. (Kuchh zameen se zyada nahin hai) ishara hai kisi cheez ki, aur (burger nahin bhi hai) ishara hai kisi cheez ki jise burger kehte hain, lekin yeh kuchh zameen se zyada nahin hai. \\n\\nIs joke ki maanani, yeh ek burger hai jo kisi zameen se adhik nahin hai, magar yeh burger hai jisne ek zameen se adhik zameen ko apne pass kar liya hai, aur yeh zameen uske pas hai, lekin yeh burger wahi hai, jo kisi zameen se adhik nahin hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 183, 'prompt_tokens': 43, 'total_tokens': 226, 'completion_time': 0.360558966, 'prompt_time': 0.05391899, 'queue_time': 0.104946539, 'total_time': 0.414477956}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d0c8d0a1-db07-428b-8974-6c71c0f0d479-0', usage_metadata={'input_tokens': 43, 'output_tokens': 183, 'total_tokens': 226})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='ÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’:\\n\\nÙ¾ÛŒØ²Ø§\\n\\nØ§Ù† Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª ÛŒÛ ÛÛ’:\\n\\nØ§ÛŒÚ© Ø´Ø®Øµ Ù†Û’ Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ú©Ùˆ Ù¾ÛÙ†Ú†Ø§ÛŒØ§ Ø§ÙˆØ± Ú©ÛØ§ØŒ \"Ø¢Ø¬ ØªÙˆ Ù…ÛŒØ±Û’ Ù„ÛŒÛ’ ÛÛŒ Ù¾ÛŒØ²Ø§ Ù„Ø§Ø¦ÛŒ ÛÙˆÚºØŒ Ù„ÛŒÚ©Ù† Ù…ÛŒÚº Ù†Û’ Ø³ÙˆÚ†Ø§ ÛÛ’ Ú©Û ØªÙˆ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛÛ’ ÛÙˆ Ú¯Ø§Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ù¾ÙˆÚ†Ú¾Ø§ØŒ \"Ú©ÛŒØ§ ØªÙˆ ÛÛ’ØŸ Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ù¾ÛÙ„Û’ ÛÛŒ Ú©ÛØ§ ØªÚ¾Ø§ Ú©Û Ù…Ø¬Ú¾Û’ Ù¾ÛŒØ²Ø§ Ù†ÛÛŒÚº Ú©Ú¾Ø§Ù†Û’ Ø¯Û’Û”\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§ÛŒØ³Ø§ ÛÛŒ ØªÙˆ Ù†ÛÛŒÚºØŒ ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù…ÛŒÚº Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛØªØ§ ÛÙˆÚºÛ”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛŒØ§ Ú©ÛØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ Ù…ÛŒÚº Ù†Û’ Ú©Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø§Ø¹Ù„Ø§Ù† Ù†ÛÛŒÚº Ú©ÛŒØ§ ØªÚ¾Ø§Û” Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¨Ø¹Ø¯ØŒ Ù¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ú©ÛŒØ§ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ù†ÛÛŒÚº Ø¯ÛŒØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø¬ÛŒ ÛØ§Úº ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’ØŒ Ù¾ÛŒØ²Ø§Û”\"\\n\\nÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’ Ú©Û Ø¬Ø¨ Ø¯ÙˆØ³Ø±Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ Ú©Û \"Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’\" ØªÙˆ Ø§Ø³ Ú©Û’ Ù…Ø¹Ù†ÛŒ Ù…ÛŒÚº \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù…\" Ú©ÛÛ’ Ú¯Ø¦Û’Û”', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c3af-62b1-8004-a8dc12753a75'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-09-06T20:24:00.244182+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c3ad-6bbf-8003-549157335226'}}, tasks=(PregelTask(id='ffb20ec9-fd39-c70c-2a72-f9d1015debe2', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the burger in a bad mood? \\n\\nBecause it had a beef with everything.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 46, 'total_tokens': 65, 'completion_time': 0.027816835, 'prompt_time': 0.093438171, 'queue_time': 0.249228309, 'total_time': 0.121255006}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--059d69f8-5cf2-4344-a35a-ab8b79d87772-0', usage_metadata={'input_tokens': 46, 'output_tokens': 19, 'total_tokens': 65})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='ÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’:\\n\\nÙ¾ÛŒØ²Ø§\\n\\nØ§Ù† Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª ÛŒÛ ÛÛ’:\\n\\nØ§ÛŒÚ© Ø´Ø®Øµ Ù†Û’ Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ú©Ùˆ Ù¾ÛÙ†Ú†Ø§ÛŒØ§ Ø§ÙˆØ± Ú©ÛØ§ØŒ \"Ø¢Ø¬ ØªÙˆ Ù…ÛŒØ±Û’ Ù„ÛŒÛ’ ÛÛŒ Ù¾ÛŒØ²Ø§ Ù„Ø§Ø¦ÛŒ ÛÙˆÚºØŒ Ù„ÛŒÚ©Ù† Ù…ÛŒÚº Ù†Û’ Ø³ÙˆÚ†Ø§ ÛÛ’ Ú©Û ØªÙˆ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛÛ’ ÛÙˆ Ú¯Ø§Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ù¾ÙˆÚ†Ú¾Ø§ØŒ \"Ú©ÛŒØ§ ØªÙˆ ÛÛ’ØŸ Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ù¾ÛÙ„Û’ ÛÛŒ Ú©ÛØ§ ØªÚ¾Ø§ Ú©Û Ù…Ø¬Ú¾Û’ Ù¾ÛŒØ²Ø§ Ù†ÛÛŒÚº Ú©Ú¾Ø§Ù†Û’ Ø¯Û’Û”\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§ÛŒØ³Ø§ ÛÛŒ ØªÙˆ Ù†ÛÛŒÚºØŒ ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù…ÛŒÚº Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛØªØ§ ÛÙˆÚºÛ”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛŒØ§ Ú©ÛØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ Ù…ÛŒÚº Ù†Û’ Ú©Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø§Ø¹Ù„Ø§Ù† Ù†ÛÛŒÚº Ú©ÛŒØ§ ØªÚ¾Ø§Û” Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¨Ø¹Ø¯ØŒ Ù¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ú©ÛŒØ§ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ù†ÛÛŒÚº Ø¯ÛŒØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø¬ÛŒ ÛØ§Úº ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’ØŒ Ù¾ÛŒØ²Ø§Û”\"\\n\\nÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’ Ú©Û Ø¬Ø¨ Ø¯ÙˆØ³Ø±Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ Ú©Û \"Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’\" ØªÙˆ Ø§Ø³ Ú©Û’ Ù…Ø¹Ù†ÛŒ Ù…ÛŒÚº \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù…\" Ú©ÛÛ’ Ú¯Ø¦Û’Û”', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c3ad-6bbf-8003-549157335226'}}, metadata={'source': 'input', 'step': 3, 'parents': {}}, created_at='2025-09-06T20:24:00.243594+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c36b-6eda-8002-6c91add157e9'}}, tasks=(PregelTask(id='1cc35dee-f80b-103b-14bb-132f66c66400', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'burger'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='ÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’:\\n\\nÙ¾ÛŒØ²Ø§\\n\\nØ§Ù† Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª ÛŒÛ ÛÛ’:\\n\\nØ§ÛŒÚ© Ø´Ø®Øµ Ù†Û’ Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ú©Ùˆ Ù¾ÛÙ†Ú†Ø§ÛŒØ§ Ø§ÙˆØ± Ú©ÛØ§ØŒ \"Ø¢Ø¬ ØªÙˆ Ù…ÛŒØ±Û’ Ù„ÛŒÛ’ ÛÛŒ Ù¾ÛŒØ²Ø§ Ù„Ø§Ø¦ÛŒ ÛÙˆÚºØŒ Ù„ÛŒÚ©Ù† Ù…ÛŒÚº Ù†Û’ Ø³ÙˆÚ†Ø§ ÛÛ’ Ú©Û ØªÙˆ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛÛ’ ÛÙˆ Ú¯Ø§Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ù¾ÙˆÚ†Ú¾Ø§ØŒ \"Ú©ÛŒØ§ ØªÙˆ ÛÛ’ØŸ Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ù¾ÛÙ„Û’ ÛÛŒ Ú©ÛØ§ ØªÚ¾Ø§ Ú©Û Ù…Ø¬Ú¾Û’ Ù¾ÛŒØ²Ø§ Ù†ÛÛŒÚº Ú©Ú¾Ø§Ù†Û’ Ø¯Û’Û”\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§ÛŒØ³Ø§ ÛÛŒ ØªÙˆ Ù†ÛÛŒÚºØŒ ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù…ÛŒÚº Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛØªØ§ ÛÙˆÚºÛ”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛŒØ§ Ú©ÛØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ Ù…ÛŒÚº Ù†Û’ Ú©Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø§Ø¹Ù„Ø§Ù† Ù†ÛÛŒÚº Ú©ÛŒØ§ ØªÚ¾Ø§Û” Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¨Ø¹Ø¯ØŒ Ù¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ú©ÛŒØ§ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ù†ÛÛŒÚº Ø¯ÛŒØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø¬ÛŒ ÛØ§Úº ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’ØŒ Ù¾ÛŒØ²Ø§Û”\"\\n\\nÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’ Ú©Û Ø¬Ø¨ Ø¯ÙˆØ³Ø±Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ Ú©Û \"Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’\" ØªÙˆ Ø§Ø³ Ú©Û’ Ù…Ø¹Ù†ÛŒ Ù…ÛŒÚº \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù…\" Ú©ÛÛ’ Ú¯Ø¦Û’Û”', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c36b-6eda-8002-6c91add157e9'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T20:24:00.216627+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4e3e-6a5a-8001-2547abe51d3c'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4e3e-6a5a-8001-2547abe51d3c'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T20:23:47.929740+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a3a-6738-8000-def77a234269'}}, tasks=(PregelTask(id='6e8d07df-662b-c158-c14e-c2373b21ec3e', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='ÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’:\\n\\nÙ¾ÛŒØ²Ø§\\n\\nØ§Ù† Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª ÛŒÛ ÛÛ’:\\n\\nØ§ÛŒÚ© Ø´Ø®Øµ Ù†Û’ Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ú©Ùˆ Ù¾ÛÙ†Ú†Ø§ÛŒØ§ Ø§ÙˆØ± Ú©ÛØ§ØŒ \"Ø¢Ø¬ ØªÙˆ Ù…ÛŒØ±Û’ Ù„ÛŒÛ’ ÛÛŒ Ù¾ÛŒØ²Ø§ Ù„Ø§Ø¦ÛŒ ÛÙˆÚºØŒ Ù„ÛŒÚ©Ù† Ù…ÛŒÚº Ù†Û’ Ø³ÙˆÚ†Ø§ ÛÛ’ Ú©Û ØªÙˆ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛÛ’ ÛÙˆ Ú¯Ø§Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ù¾ÙˆÚ†Ú¾Ø§ØŒ \"Ú©ÛŒØ§ ØªÙˆ ÛÛ’ØŸ Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ù¾ÛÙ„Û’ ÛÛŒ Ú©ÛØ§ ØªÚ¾Ø§ Ú©Û Ù…Ø¬Ú¾Û’ Ù¾ÛŒØ²Ø§ Ù†ÛÛŒÚº Ú©Ú¾Ø§Ù†Û’ Ø¯Û’Û”\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§ÛŒØ³Ø§ ÛÛŒ ØªÙˆ Ù†ÛÛŒÚºØŒ ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù…ÛŒÚº Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛØªØ§ ÛÙˆÚºÛ”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛŒØ§ Ú©ÛØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"ØªÙˆ Ù†Û’ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ Ù…ÛŒÚº Ù†Û’ Ú©Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø§Ø¹Ù„Ø§Ù† Ù†ÛÛŒÚº Ú©ÛŒØ§ ØªÚ¾Ø§Û” Ù…ÛŒÚº Ù†Û’ ØªÙˆ Ú©ÛØ§ ØªÚ¾Ø§ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¨Ø¹Ø¯ØŒ Ù¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø§Ø±Û’ Ø¨Ú¾Ø§Ø¦ÛŒØŒ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’Û”\"\\n\\nØ§Ø³ Ú©Û’ Ø¯ÙˆØ³Øª Ù†Û’ Ú©ÛØ§ØŒ \"Ú©ÛŒØ§ ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ù†ÛÛŒÚº Ø¯ÛŒØ§ ØªÚ¾Ø§ØŸ\"\\n\\nÙ¾ÛÙ„Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ØŒ \"Ø¬ÛŒ ÛØ§Úº ØªÙˆ Ù†Û’ Ù…Ø¬Ú¾Û’ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Ø§ Ù†Ø§Ù… Ø¯ÛŒØ§ ÛÛ’ØŒ Ù¾ÛŒØ²Ø§Û”\"\\n\\nÛŒÛ Ø¬ÙˆÚ© ÛŒÛ ÛÛ’ Ú©Û Ø¬Ø¨ Ø¯ÙˆØ³Ø±Û’ Ø´Ø®Øµ Ù†Û’ Ú©ÛØ§ Ú©Û \"Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’\" ØªÙˆ Ø§Ø³ Ú©Û’ Ù…Ø¹Ù†ÛŒ Ù…ÛŒÚº \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù…\" Ú©ÛÛ’ Ú¯Ø¦Û’Û”', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a3a-6738-8000-def77a234269'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:23:47.508602+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a38-66e1-bfff-11cf76741ec8'}}, tasks=(PregelTask(id='8aaa9cd6-4e7c-0ddc-9aad-8cae1b53133f', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a38-66e1-bfff-11cf76741ec8'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T20:23:47.507781+00:00', parent_config=None, tasks=(PregelTask(id='bf4660b1-f56b-cc2f-622e-b1022a55a932', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chatbot.get_state_history(config=config2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f3ea65",
   "metadata": {},
   "source": [
    "# persistent in langgraph\n",
    "Persistence in LangGraph means saving the memory and state of your AI workflow (graph) so it doesnâ€™t get lost when something goes wrong or when you want to resume later.\n",
    "\n",
    "Think of it like a save game feature in a video game.\n",
    "\n",
    "- Without persistence â†’ if the game crashes, you lose progress.\n",
    "\n",
    "- With persistence â†’ you reload from the last checkpoint.\n",
    "\n",
    "So in LangGraph, persistence allows your workflow to survive crashes, restarts, or interruptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939fe3c",
   "metadata": {},
   "source": [
    "# Fault tolerance\n",
    "Fault tolerance means the system can recover from errors without starting everything from scratch.\n",
    "\n",
    "Persistence helps by:\n",
    "\n",
    "- Saving progress at certain steps (checkpoints).\n",
    "\n",
    "- If an error or crash happens, the graph reloads from the last checkpoint instead of starting at the beginning.\n",
    "\n",
    "- This makes the system more reliable and faster because you donâ€™t redo completed steps.\n",
    "\n",
    "ğŸ”¹ Example:\n",
    "Imagine you are building a workflow that processes a customerâ€™s request in 5 steps:\n",
    "\n",
    "- Validate user input\n",
    "\n",
    "- Retrieve information from a database\n",
    "\n",
    "- Summarize the data\n",
    "\n",
    "- Generate a response\n",
    "\n",
    "- Send it back to the user\n",
    "\n",
    "If the system crashes at step 4:\n",
    "\n",
    "- Without persistence â†’ you must start again from step 1.\n",
    "\n",
    "- With persistence â†’ you restart from step 3 or 4 (where you last saved).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7d52a",
   "metadata": {},
   "source": [
    "# checkpointers in persistent\n",
    "Checkpointers are like â€œsave pointsâ€ in a workflow.\n",
    "\n",
    "- They store the state (data, inputs, outputs) of the workflow at specific moments.\n",
    "\n",
    "- Later, you can reload the workflow from that checkpoint.\n",
    "\n",
    "ğŸ”¹ Example:\n",
    "Think of an online exam system:\n",
    "\n",
    "- Every 5 minutes, it autosaves your answers (checkpoints).\n",
    "\n",
    "- If your laptop shuts down, when you log back in, your answers up to the last save are still there.\n",
    "\n",
    "In LangGraph, checkpointers do the same thing for AI workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de1692",
   "metadata": {},
   "source": [
    "# Threads in persistent\n",
    "\n",
    "A thread is like a separate conversation or workflow instance that gets its own saved state.\n",
    "\n",
    "- Each thread has its own memory and checkpoints.\n",
    "\n",
    "- You can pause one thread and start another, then come back later.\n",
    "\n",
    "ğŸ”¹ Example:\n",
    "Think of WhatsApp chats:\n",
    "\n",
    "- Each chat with a person is like a â€œthread.â€\n",
    "\n",
    "- Messages are saved (persistent), so when you reopen the chat, you see the history.\n",
    "\n",
    "- Each conversation is independent of the others.\n",
    "\n",
    "In LangGraph, threads let you manage multiple workflows (conversations, tasks, or jobs) at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2328b",
   "metadata": {},
   "source": [
    "# benefits of Persistent\n",
    "- Short term Memory\n",
    "- Fault Tolerance\n",
    "- Human in the loop\n",
    "- Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21454155",
   "metadata": {},
   "source": [
    "# MemorySaver vs InMemorySaver\n",
    "- InMemorySaver â†’ Very simple saver, keeps checkpoints only in RAM, lost when program ends. Good for quick testing.\n",
    "\n",
    "- MemorySaver â†’ Higher-level saver that organizes checkpoints per thread for LangGraph workflows. Still in-memory, but structured for persistence during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e13759a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from typing import  Annotated,TypedDict\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d776f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class state(TypedDict):\n",
    "    topic:str\n",
    "    joke:str\n",
    "    explain:str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a53f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model='llama-3.1-8b-instant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f6a8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_gen(state:state):\n",
    "    prompt=f\"Generate the short joke on the foolowing topic :{state['topic']}\"\n",
    "    response=llm.invoke(prompt)\n",
    "    return {'joke':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a18e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_exp(state:state):\n",
    "    prompt=f\"explain the following joke in urdu {state['topic']}\"\n",
    "    exp=llm.invoke(prompt)\n",
    "    return {'explain':exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b560e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(state)\n",
    "graph.add_node('joke_gen',joke_gen)\n",
    "graph.add_node('joke_exp',joke_exp)\n",
    "\n",
    "graph.add_edge(START,'joke_gen')\n",
    "graph.add_edge('joke_gen','joke_exp')\n",
    "graph.add_edge('joke_exp',END)\n",
    "\n",
    "checkpointer=InMemorySaver()\n",
    "chatbot=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae4c5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0e27f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'configurable':{'thread_id':thread_id}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'pizza'},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "473c0f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}),\n",
       " 'explain': AIMessage(content='Pizza Ú©Ø§ ÛŒÛ Ø¬ÙˆÚ© ÛÛ’:\\n\\n\" Pizza Ø§ÛŒÚ© Ø®Ø§ØªÙˆÙ† Ø³Û’ Ù¾ÙˆÚ†Ú¾Ø§ Ú¯ÛŒØ§ Ú©Û ÙˆÛ Ú©ÛŒØ§ ÛÛ’Û” ÙˆÛ Ú©ÛÙ†Û’ Ù„Ú¯ÛŒ Ú©Û Ù…ÛŒÚº Ø§ÛŒÚ© Ù¾ÛŒØ²Ø§ ÛÙˆÚºÛ” Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'Ú©ÛŒØ§ Ø¢Ù¾ Ú©Û’ Ù…Ø§Úº Ø¨Ø§Ù¾ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ ÛÛŒÚºØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÛØ§ÚºØŒ ÙˆÛ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ Ø¢Ù¾ Ú©Û’ ÚˆÛŒÚˆÛŒ Ú©Ø§ Ø¯Ø§Ú‘Ú¾ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÙˆÛ Ù…ÛŒØ±Û’ Ø³Ø± Ú©Û’ Ø§ÙˆÙ¾Ø± ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ Ø¢Ù¾ Ú©Û’ Ø¨Ø§Ù¾ Ú©Ø§ Ø¯Ø§Ú‘Ú¾ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÙˆÛ Ù…ÛŒØ±Û’ Ø³Ø± Ú©Û’ Ø§ÙˆÙ¾Ø± ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ ÛŒÛ Ø¢Ù¾ Ú©ÛŒ Ù…Ø§Úº Ø¨Ø§Ù¾ ÛÛŒÚºØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÛØ§ÚºØŒ ÛŒÛ Ù…ÛŒÚº ÛÛŒ ÛÙˆÚºÛ”\\'\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 43, 'total_tokens': 414, 'completion_time': 0.494079589, 'prompt_time': 0.030879016, 'queue_time': 0.129438743, 'total_time': 0.524958605}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b2de9c0-85d6-42f8-881a-4539bff92076-0', usage_metadata={'input_tokens': 43, 'output_tokens': 371, 'total_tokens': 414})}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8f1121",
   "metadata": {},
   "source": [
    "# Fault tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ca191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_gen1(state:state):\n",
    "    prompt=f\"Generate the short joke on the foolowing topic :{state['topic']}\"\n",
    "    response=llm.invoke(prompt)\n",
    "    print('Generation completed...')\n",
    "    return {'joke':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62165a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # let llm take time to resposne so we can interrupt our  system for trying fault tolerance\n",
    "def joke_exp1(state:state):\n",
    "    prompt=f\"explain the following joke in urdu {state['topic']}\"\n",
    "    time.sleep(10)\n",
    "    exp=llm.invoke(prompt)\n",
    "    print('Explanation completed...')\n",
    "\n",
    "    return {'explain':exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d97b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(state)\n",
    "graph.add_node('joke_gen1',joke_gen1)\n",
    "graph.add_node('joke_exp1',joke_exp1)\n",
    "\n",
    "graph.add_edge(START,'joke_gen1')\n",
    "graph.add_edge('joke_gen1','joke_exp1')\n",
    "graph.add_edge('joke_exp1',END)\n",
    "\n",
    "checkpointer=InMemorySaver()\n",
    "chatbot=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8891112",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id_n='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b64fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation completed...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 2\u001b[39m\n",
      "\u001b[32m      1\u001b[39m config2={\u001b[33m'\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m'\u001b[39m:{\u001b[33m'\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m'\u001b[39m:thread_id_n}}\n",
      "\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result=\u001b[43mchatbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpizza\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig2\u001b[49m\n",
      "\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n",
      "\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n",
      "\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n",
      "\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n",
      "\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n",
      "\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n",
      "\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n",
      "\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n",
      "\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n",
      "\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n",
      "\u001b[32m     40\u001b[39m     task.writes.clear()\n",
      "\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n",
      "\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n",
      "\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n",
      "\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n",
      "\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n",
      "\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mjoke_exp1\u001b[39m\u001b[34m(state)\u001b[39m\n",
      "\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjoke_exp1\u001b[39m(state:state):\n",
      "\u001b[32m      3\u001b[39m     prompt=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexplain the following joke in urdu \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m'\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m      5\u001b[39m     exp=llm.invoke(prompt)\n",
      "\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mExplanation completed...\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'pizza'},\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d73ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016743983, 'prompt_time': 0.005746572, 'queue_time': 0.048494358, 'total_time': 0.022490555}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f941491b-1c03-48ef-9578-2cf1f92f58b3-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}),\n",
       " 'explain': AIMessage(content='Koi joke hai: Pizza\\n\\nYeh joke yeh hai: koi pizza parlor hai jahan par ek customer aata hai aur order karta hai: \"Maine apne dost ko pizza khaane ke liye kaha hai, lekin wo pizza kheena nahin khata. Main apne dost ko pizza khaane ke liye bolun, lekin use pizza kheena nahin khana hai.\"\\n\\nPizza parlor owner bolta hai: \"Aapko kya problem hai? Maine aapke dost ko pizza kheena nahin khaana hai.\"\\n\\nCustomer bolta hai: \"Arre, main usko pizza kheena nahin khana hai, main usko khana hai, lekin usse pizza kheena nahin khana hai.\"\\n\\nYeh joke ek akhbari shaili mehsoos hota hai, jahan par ek customer usse keh raha hai ki uska dost pizza kheena nahin khata, lekin uska dost usse keh raha hai ki woh khana nahin khata, balki woh pizza kheena khana nahin chahta. Yeh joke ek akarshak aur majedar joke hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 265, 'prompt_tokens': 43, 'total_tokens': 308, 'completion_time': 0.502257352, 'prompt_time': 0.005772792, 'queue_time': 0.048120317, 'total_time': 0.508030144}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--99ada6d7-e99d-43ff-a9eb-d7d0df3f1e02-0', usage_metadata={'input_tokens': 43, 'output_tokens': 265, 'total_tokens': 308})}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe236a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation completed...\n"
     ]
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    None,\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13c057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T15:52:25.846489+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-ecca-63a1-8001-fcf36c54577b'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-ecca-63a1-8001-fcf36c54577b'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T15:34:36.780413+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e354-62c0-8000-09640931bb8d'}}, tasks=(PregelTask(id='61d7e66b-c5b3-eb25-0a51-8a638d7af224', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e354-62c0-8000-09640931bb8d'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T15:34:35.788352+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e352-6e90-bfff-e6c7952562fd'}}, tasks=(PregelTask(id='290746e0-7676-e7e0-e56d-a22cdbd9b7f2', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e352-6e90-bfff-e6c7952562fd'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T15:34:35.787833+00:00', parent_config=None, tasks=(PregelTask(id='9bd735fb-22ed-9dd6-2dbd-ff3dbda3d861', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list(chatbot.get_state_history(config=config2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d71a2",
   "metadata": {},
   "source": [
    "# Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d07490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation completed...\n",
      "Explanation completed...\n"
     ]
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'burger'},\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=list(chatbot.get_state_history(config=config2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8c08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why did the burger go to therapy? \\n\\nBecause it was feeling a little crumby.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.018759797, 'prompt_time': 0.10406644, 'queue_time': 0.06509964, 'total_time': 0.122826237}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--844c251c-aedd-42fe-9c41-29da55b480f6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Main ne ek burger ko pehli bar dekha tha aur usne mere se poocha, \"Kya tum mujhe khatam kar sakte ho?\"\\n\\nMain ne kehna shuru kiya, \"Kuch hi karunga, main aapko khatam to kar sakta hoon, lekin aapko khaane mein behter lagta hai.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 43, 'total_tokens': 125, 'completion_time': 0.214847333, 'prompt_time': 0.043010094, 'queue_time': 0.055033355, 'total_time': 0.257857427}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--757c9bd5-02a7-44b3-a222-64a1258853a6-0', usage_metadata={'input_tokens': 43, 'output_tokens': 82, 'total_tokens': 125})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-92ef-6c7f-8006-fc5aeae87213'}}, metadata={'source': 'loop', 'step': 6, 'parents': {}}, created_at='2025-09-06T15:55:02.161687+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-2841-66b8-8005-45cbc0103953'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why did the burger go to therapy? \\n\\nBecause it was feeling a little crumby.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.018759797, 'prompt_time': 0.10406644, 'queue_time': 0.06509964, 'total_time': 0.122826237}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--844c251c-aedd-42fe-9c41-29da55b480f6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-2841-66b8-8005-45cbc0103953'}}, metadata={'source': 'loop', 'step': 5, 'parents': {}}, created_at='2025-09-06T15:54:50.975384+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f88-6f55-8004-f7a50feb3c58'}}, tasks=(PregelTask(id='b5e51c1f-2554-1f4b-7731-23a0d37cada4', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Main ne ek burger ko pehli bar dekha tha aur usne mere se poocha, \"Kya tum mujhe khatam kar sakte ho?\"\\n\\nMain ne kehna shuru kiya, \"Kuch hi karunga, main aapko khatam to kar sakta hoon, lekin aapko khaane mein behter lagta hai.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 43, 'total_tokens': 125, 'completion_time': 0.214847333, 'prompt_time': 0.043010094, 'queue_time': 0.055033355, 'total_time': 0.257857427}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--757c9bd5-02a7-44b3-a222-64a1258853a6-0', usage_metadata={'input_tokens': 43, 'output_tokens': 82, 'total_tokens': 125})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f88-6f55-8004-f7a50feb3c58'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-09-06T15:54:50.060979+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f87-6a3c-8003-2954195c3dcc'}}, tasks=(PregelTask(id='5d4e98a3-1677-fe3f-e076-7cfcca706710', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the burger go to therapy? \\n\\nBecause it was feeling a little crumby.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.018759797, 'prompt_time': 0.10406644, 'queue_time': 0.06509964, 'total_time': 0.122826237}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--844c251c-aedd-42fe-9c41-29da55b480f6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f87-6a3c-8003-2954195c3dcc'}}, metadata={'source': 'input', 'step': 3, 'parents': {}}, created_at='2025-09-06T15:54:50.060437+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}}, tasks=(PregelTask(id='3e656e65-42e1-2c6c-907f-5e68811f95a7', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'burger'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T15:52:25.846489+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-ecca-63a1-8001-fcf36c54577b'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-ecca-63a1-8001-fcf36c54577b'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T15:34:36.780413+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e354-62c0-8000-09640931bb8d'}}, tasks=(PregelTask(id='61d7e66b-c5b3-eb25-0a51-8a638d7af224', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e354-62c0-8000-09640931bb8d'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T15:34:35.788352+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e352-6e90-bfff-e6c7952562fd'}}, tasks=(PregelTask(id='290746e0-7676-e7e0-e56d-a22cdbd9b7f2', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e352-6e90-bfff-e6c7952562fd'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T15:34:35.787833+00:00', parent_config=None, tasks=(PregelTask(id='9bd735fb-22ed-9dd6-2dbd-ff3dbda3d861', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a1596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-92ef-6c7f-8006-fc5aeae87213'}} {'topic': 'burger', 'joke': AIMessage(content='Why did the burger go to therapy? \\n\\nBecause it was feeling a little crumby.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.018759797, 'prompt_time': 0.10406644, 'queue_time': 0.06509964, 'total_time': 0.122826237}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--844c251c-aedd-42fe-9c41-29da55b480f6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Main ne ek burger ko pehli bar dekha tha aur usne mere se poocha, \"Kya tum mujhe khatam kar sakte ho?\"\\n\\nMain ne kehna shuru kiya, \"Kuch hi karunga, main aapko khatam to kar sakta hoon, lekin aapko khaane mein behter lagta hai.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 43, 'total_tokens': 125, 'completion_time': 0.214847333, 'prompt_time': 0.043010094, 'queue_time': 0.055033355, 'total_time': 0.257857427}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--757c9bd5-02a7-44b3-a222-64a1258853a6-0', usage_metadata={'input_tokens': 43, 'output_tokens': 82, 'total_tokens': 125})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-2841-66b8-8005-45cbc0103953'}} {'topic': 'burger', 'joke': AIMessage(content='Why did the burger go to therapy? \\n\\nBecause it was feeling a little crumby.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.018759797, 'prompt_time': 0.10406644, 'queue_time': 0.06509964, 'total_time': 0.122826237}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--844c251c-aedd-42fe-9c41-29da55b480f6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f88-6f55-8004-f7a50feb3c58'}} {'topic': 'burger', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f87-6a3c-8003-2954195c3dcc'}} {'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}} {'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-ecca-63a1-8001-fcf36c54577b'}} {'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e354-62c0-8000-09640931bb8d'}} {'topic': 'pizza'}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e352-6e90-bfff-e6c7952562fd'}} {}\n"
     ]
    }
   ],
   "source": [
    "for i in history:\n",
    "    print(i.config,i.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f99c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n,'checkpoint_id':'1f08b397-c032-6d17-8002-93219853b5ad'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ea31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}),\n",
       " 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chatbot.invoke(None,config=config2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9195d85",
   "metadata": {},
   "source": [
    "# update state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2797082c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f08b607-050b-61ea-8000-c51873769598'}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.update_state(\n",
    "    config={\n",
    "        'configurable':{\n",
    "            'thread_id':'1',\n",
    "            'checkpoint_id':'1f08b397-c032-6d17-8002-93219853b5ad',\n",
    "            'checkpoint_ns':''\n",
    "            }\n",
    "            },\n",
    "                     values={'topic':'fries'}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b6d0c10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'fries'}, next=('joke_gen',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b607-050b-61ea-8000-c51873769598'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:31:16.594322+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}}, tasks=(PregelTask(id='37a89252-caa4-4d3c-f6ee-4d1f22a95ce8', name='joke_gen', path=('__pregel_pull', 'joke_gen'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='Pizza Ú©Ø§ ÛŒÛ Ø¬ÙˆÚ© ÛÛ’:\\n\\n\" Pizza Ø§ÛŒÚ© Ø®Ø§ØªÙˆÙ† Ø³Û’ Ù¾ÙˆÚ†Ú¾Ø§ Ú¯ÛŒØ§ Ú©Û ÙˆÛ Ú©ÛŒØ§ ÛÛ’Û” ÙˆÛ Ú©ÛÙ†Û’ Ù„Ú¯ÛŒ Ú©Û Ù…ÛŒÚº Ø§ÛŒÚ© Ù¾ÛŒØ²Ø§ ÛÙˆÚºÛ” Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'Ú©ÛŒØ§ Ø¢Ù¾ Ú©Û’ Ù…Ø§Úº Ø¨Ø§Ù¾ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ ÛÛŒÚºØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÛØ§ÚºØŒ ÙˆÛ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ Ø¢Ù¾ Ú©Û’ ÚˆÛŒÚˆÛŒ Ú©Ø§ Ø¯Ø§Ú‘Ú¾ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÙˆÛ Ù…ÛŒØ±Û’ Ø³Ø± Ú©Û’ Ø§ÙˆÙ¾Ø± ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ Ø¢Ù¾ Ú©Û’ Ø¨Ø§Ù¾ Ú©Ø§ Ø¯Ø§Ú‘Ú¾ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÙˆÛ Ù…ÛŒØ±Û’ Ø³Ø± Ú©Û’ Ø§ÙˆÙ¾Ø± ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ ÛŒÛ Ø¢Ù¾ Ú©ÛŒ Ù…Ø§Úº Ø¨Ø§Ù¾ ÛÛŒÚºØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÛØ§ÚºØŒ ÛŒÛ Ù…ÛŒÚº ÛÛŒ ÛÙˆÚºÛ”\\'\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 43, 'total_tokens': 414, 'completion_time': 0.494079589, 'prompt_time': 0.030879016, 'queue_time': 0.129438743, 'total_time': 0.524958605}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b2de9c0-85d6-42f8-881a-4539bff92076-0', usage_metadata={'input_tokens': 43, 'output_tokens': 371, 'total_tokens': 414})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-8511-676b-8002-371af2ae002d'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T20:25:14.209047+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7cf8-617e-8001-051cb2c8452d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}, next=('joke_exp',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7cf8-617e-8001-051cb2c8452d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T20:25:13.359792+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7042-6fea-8000-03aeef0670aa'}}, tasks=(PregelTask(id='84a8ab59-da35-b15f-8f39-fcd939179d32', name='joke_exp', path=('__pregel_pull', 'joke_exp'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Pizza Ú©Ø§ ÛŒÛ Ø¬ÙˆÚ© ÛÛ’:\\n\\n\" Pizza Ø§ÛŒÚ© Ø®Ø§ØªÙˆÙ† Ø³Û’ Ù¾ÙˆÚ†Ú¾Ø§ Ú¯ÛŒØ§ Ú©Û ÙˆÛ Ú©ÛŒØ§ ÛÛ’Û” ÙˆÛ Ú©ÛÙ†Û’ Ù„Ú¯ÛŒ Ú©Û Ù…ÛŒÚº Ø§ÛŒÚ© Ù¾ÛŒØ²Ø§ ÛÙˆÚºÛ” Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'Ú©ÛŒØ§ Ø¢Ù¾ Ú©Û’ Ù…Ø§Úº Ø¨Ø§Ù¾ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ ÛÛŒÚºØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÛØ§ÚºØŒ ÙˆÛ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ Ø¢Ù¾ Ú©Û’ ÚˆÛŒÚˆÛŒ Ú©Ø§ Ø¯Ø§Ú‘Ú¾ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÙˆÛ Ù…ÛŒØ±Û’ Ø³Ø± Ú©Û’ Ø§ÙˆÙ¾Ø± ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ Ø¢Ù¾ Ú©Û’ Ø¨Ø§Ù¾ Ú©Ø§ Ø¯Ø§Ú‘Ú¾ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÙˆÛ Ù…ÛŒØ±Û’ Ø³Ø± Ú©Û’ Ø§ÙˆÙ¾Ø± ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ ÛŒÛ Ø¢Ù¾ Ú©ÛŒ Ù…Ø§Úº Ø¨Ø§Ù¾ ÛÛŒÚºØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÛØ§ÚºØŒ ÛŒÛ Ù…ÛŒÚº ÛÛŒ ÛÙˆÚºÛ”\\'\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 43, 'total_tokens': 414, 'completion_time': 0.494079589, 'prompt_time': 0.030879016, 'queue_time': 0.129438743, 'total_time': 0.524958605}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b2de9c0-85d6-42f8-881a-4539bff92076-0', usage_metadata={'input_tokens': 43, 'output_tokens': 371, 'total_tokens': 414})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7042-6fea-8000-03aeef0670aa'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:25:12.027332+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7041-6bfd-bfff-fa05f68fecb5'}}, tasks=(PregelTask(id='52104c82-77f3-2dfc-214d-03bcf4bf9800', name='joke_gen', path=('__pregel_pull', 'joke_gen'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7041-6bfd-bfff-fa05f68fecb5'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T20:25:12.026824+00:00', parent_config=None, tasks=(PregelTask(id='a8c8bcc9-e509-4827-3d02-920637aea71d', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chatbot.get_state_history(config={'configurable':{'thread_id':'1'}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f39b0792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'fries',\n",
       " 'joke': AIMessage(content='Why did the fries go to therapy? \\n\\nBecause they were struggling to cope with the heat of the moment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 47, 'total_tokens': 70, 'completion_time': 0.042605748, 'prompt_time': 0.016848542, 'queue_time': 0.090819568, 'total_time': 0.05945429}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4a8b8990-a5ae-413e-b3bd-592a615b9f6f-0', usage_metadata={'input_tokens': 47, 'output_tokens': 23, 'total_tokens': 70}),\n",
       " 'explain': AIMessage(content='Main samajh nahi sakta ki kya joke diya gaya hai. Kya aap is joke ko explain karne ke liye ready hain?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 43, 'total_tokens': 79, 'completion_time': 0.068504242, 'prompt_time': 0.012168159, 'queue_time': 0.125282411, 'total_time': 0.080672401}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ce014bf-0a1a-470a-a07e-69f045be88f3-0', usage_metadata={'input_tokens': 43, 'output_tokens': 36, 'total_tokens': 79})}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(\n",
    "    None,config={\n",
    "        'configurable':{'thread_id':'1','checkpoint_id':'1f08b607-050b-61ea-8000-c51873769598'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f8f40175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'fries', 'joke': AIMessage(content='Why did the fries go to therapy? \\n\\nBecause they were struggling to cope with the heat of the moment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 47, 'total_tokens': 70, 'completion_time': 0.042605748, 'prompt_time': 0.016848542, 'queue_time': 0.090819568, 'total_time': 0.05945429}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4a8b8990-a5ae-413e-b3bd-592a615b9f6f-0', usage_metadata={'input_tokens': 47, 'output_tokens': 23, 'total_tokens': 70}), 'explain': AIMessage(content='Main samajh nahi sakta ki kya joke diya gaya hai. Kya aap is joke ko explain karne ke liye ready hain?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 43, 'total_tokens': 79, 'completion_time': 0.068504242, 'prompt_time': 0.012168159, 'queue_time': 0.125282411, 'total_time': 0.080672401}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ce014bf-0a1a-470a-a07e-69f045be88f3-0', usage_metadata={'input_tokens': 43, 'output_tokens': 36, 'total_tokens': 79})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b614-c696-6bf8-8002-9c1d6d7e21d5'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T20:37:25.855098+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b614-c2ed-61f9-8001-9678478201c7'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'fries', 'joke': AIMessage(content='Why did the fries go to therapy? \\n\\nBecause they were struggling to cope with the heat of the moment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 47, 'total_tokens': 70, 'completion_time': 0.042605748, 'prompt_time': 0.016848542, 'queue_time': 0.090819568, 'total_time': 0.05945429}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4a8b8990-a5ae-413e-b3bd-592a615b9f6f-0', usage_metadata={'input_tokens': 47, 'output_tokens': 23, 'total_tokens': 70})}, next=('joke_exp',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b614-c2ed-61f9-8001-9678478201c7'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T20:37:25.471038+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b607-050b-61ea-8000-c51873769598'}}, tasks=(PregelTask(id='176c9260-0cc7-959f-a5a8-e873b34f407b', name='joke_exp', path=('__pregel_pull', 'joke_exp'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Main samajh nahi sakta ki kya joke diya gaya hai. Kya aap is joke ko explain karne ke liye ready hain?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 43, 'total_tokens': 79, 'completion_time': 0.068504242, 'prompt_time': 0.012168159, 'queue_time': 0.125282411, 'total_time': 0.080672401}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ce014bf-0a1a-470a-a07e-69f045be88f3-0', usage_metadata={'input_tokens': 43, 'output_tokens': 36, 'total_tokens': 79})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'fries'}, next=('joke_gen',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b607-050b-61ea-8000-c51873769598'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:31:16.594322+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}}, tasks=(PregelTask(id='37a89252-caa4-4d3c-f6ee-4d1f22a95ce8', name='joke_gen', path=('__pregel_pull', 'joke_gen'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the fries go to therapy? \\n\\nBecause they were struggling to cope with the heat of the moment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 47, 'total_tokens': 70, 'completion_time': 0.042605748, 'prompt_time': 0.016848542, 'queue_time': 0.090819568, 'total_time': 0.05945429}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4a8b8990-a5ae-413e-b3bd-592a615b9f6f-0', usage_metadata={'input_tokens': 47, 'output_tokens': 23, 'total_tokens': 70})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='Pizza Ú©Ø§ ÛŒÛ Ø¬ÙˆÚ© ÛÛ’:\\n\\n\" Pizza Ø§ÛŒÚ© Ø®Ø§ØªÙˆÙ† Ø³Û’ Ù¾ÙˆÚ†Ú¾Ø§ Ú¯ÛŒØ§ Ú©Û ÙˆÛ Ú©ÛŒØ§ ÛÛ’Û” ÙˆÛ Ú©ÛÙ†Û’ Ù„Ú¯ÛŒ Ú©Û Ù…ÛŒÚº Ø§ÛŒÚ© Ù¾ÛŒØ²Ø§ ÛÙˆÚºÛ” Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'Ú©ÛŒØ§ Ø¢Ù¾ Ú©Û’ Ù…Ø§Úº Ø¨Ø§Ù¾ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ ÛÛŒÚºØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÛØ§ÚºØŒ ÙˆÛ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ Ø¢Ù¾ Ú©Û’ ÚˆÛŒÚˆÛŒ Ú©Ø§ Ø¯Ø§Ú‘Ú¾ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÙˆÛ Ù…ÛŒØ±Û’ Ø³Ø± Ú©Û’ Ø§ÙˆÙ¾Ø± ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ Ø¢Ù¾ Ú©Û’ Ø¨Ø§Ù¾ Ú©Ø§ Ø¯Ø§Ú‘Ú¾ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÙˆÛ Ù…ÛŒØ±Û’ Ø³Ø± Ú©Û’ Ø§ÙˆÙ¾Ø± ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ ÛŒÛ Ø¢Ù¾ Ú©ÛŒ Ù…Ø§Úº Ø¨Ø§Ù¾ ÛÛŒÚºØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÛØ§ÚºØŒ ÛŒÛ Ù…ÛŒÚº ÛÛŒ ÛÙˆÚºÛ”\\'\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 43, 'total_tokens': 414, 'completion_time': 0.494079589, 'prompt_time': 0.030879016, 'queue_time': 0.129438743, 'total_time': 0.524958605}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b2de9c0-85d6-42f8-881a-4539bff92076-0', usage_metadata={'input_tokens': 43, 'output_tokens': 371, 'total_tokens': 414})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-8511-676b-8002-371af2ae002d'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T20:25:14.209047+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7cf8-617e-8001-051cb2c8452d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}, next=('joke_exp',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7cf8-617e-8001-051cb2c8452d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T20:25:13.359792+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7042-6fea-8000-03aeef0670aa'}}, tasks=(PregelTask(id='84a8ab59-da35-b15f-8f39-fcd939179d32', name='joke_exp', path=('__pregel_pull', 'joke_exp'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Pizza Ú©Ø§ ÛŒÛ Ø¬ÙˆÚ© ÛÛ’:\\n\\n\" Pizza Ø§ÛŒÚ© Ø®Ø§ØªÙˆÙ† Ø³Û’ Ù¾ÙˆÚ†Ú¾Ø§ Ú¯ÛŒØ§ Ú©Û ÙˆÛ Ú©ÛŒØ§ ÛÛ’Û” ÙˆÛ Ú©ÛÙ†Û’ Ù„Ú¯ÛŒ Ú©Û Ù…ÛŒÚº Ø§ÛŒÚ© Ù¾ÛŒØ²Ø§ ÛÙˆÚºÛ” Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'Ú©ÛŒØ§ Ø¢Ù¾ Ú©Û’ Ù…Ø§Úº Ø¨Ø§Ù¾ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ ÛÛŒÚºØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÛØ§ÚºØŒ ÙˆÛ Ø¨Ú¾ÛŒ Ù¾ÛŒØ²Ø§ ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ Ø¢Ù¾ Ú©Û’ ÚˆÛŒÚˆÛŒ Ú©Ø§ Ø¯Ø§Ú‘Ú¾ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÙˆÛ Ù…ÛŒØ±Û’ Ø³Ø± Ú©Û’ Ø§ÙˆÙ¾Ø± ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ Ø¢Ù¾ Ú©Û’ Ø¨Ø§Ù¾ Ú©Ø§ Ø¯Ø§Ú‘Ú¾ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÙˆÛ Ù…ÛŒØ±Û’ Ø³Ø± Ú©Û’ Ø§ÙˆÙ¾Ø± ÛÛŒÚºÛ”\\' Ù¾ÛŒØ²Ø§ Ù†Û’ Ú©ÛØ§ØŒ \\'ØªÙˆ ÛŒÛ Ø¢Ù¾ Ú©ÛŒ Ù…Ø§Úº Ø¨Ø§Ù¾ ÛÛŒÚºØŸ\\' Ø®Ø§ØªÙˆÙ† Ù†Û’ Ú©ÛØ§ØŒ \\'ÛØ§ÚºØŒ ÛŒÛ Ù…ÛŒÚº ÛÛŒ ÛÙˆÚºÛ”\\'\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 43, 'total_tokens': 414, 'completion_time': 0.494079589, 'prompt_time': 0.030879016, 'queue_time': 0.129438743, 'total_time': 0.524958605}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b2de9c0-85d6-42f8-881a-4539bff92076-0', usage_metadata={'input_tokens': 43, 'output_tokens': 371, 'total_tokens': 414})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7042-6fea-8000-03aeef0670aa'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:25:12.027332+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7041-6bfd-bfff-fa05f68fecb5'}}, tasks=(PregelTask(id='52104c82-77f3-2dfc-214d-03bcf4bf9800', name='joke_gen', path=('__pregel_pull', 'joke_gen'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7041-6bfd-bfff-fa05f68fecb5'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T20:25:12.026824+00:00', parent_config=None, tasks=(PregelTask(id='a8c8bcc9-e509-4827-3d02-920637aea71d', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chatbot.get_state_history(config={'configurable':{'thread_id':'1'}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e282da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
