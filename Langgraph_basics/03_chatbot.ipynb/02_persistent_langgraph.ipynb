{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db474ea",
   "metadata": {},
   "source": [
    "# persistent in langgraph\n",
    "Persistence in LangGraph means saving the memory and state of your AI workflow (graph) so it doesn’t get lost when something goes wrong or when you want to resume later.\n",
    "\n",
    "Think of it like a save game feature in a video game.\n",
    "\n",
    "- Without persistence → if the game crashes, you lose progress.\n",
    "\n",
    "- With persistence → you reload from the last checkpoint.\n",
    "\n",
    "So in LangGraph, persistence allows your workflow to survive crashes, restarts, or interruptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6788c2",
   "metadata": {},
   "source": [
    "# Fault tolerance\n",
    "Fault tolerance means the system can recover from errors without starting everything from scratch.\n",
    "\n",
    "Persistence helps by:\n",
    "\n",
    "- Saving progress at certain steps (checkpoints).\n",
    "\n",
    "- If an error or crash happens, the graph reloads from the last checkpoint instead of starting at the beginning.\n",
    "\n",
    "- This makes the system more reliable and faster because you don’t redo completed steps.\n",
    "\n",
    "🔹 Example:\n",
    "Imagine you are building a workflow that processes a customer’s request in 5 steps:\n",
    "\n",
    "- Validate user input\n",
    "\n",
    "- Retrieve information from a database\n",
    "\n",
    "- Summarize the data\n",
    "\n",
    "- Generate a response\n",
    "\n",
    "- Send it back to the user\n",
    "\n",
    "If the system crashes at step 4:\n",
    "\n",
    "- Without persistence → you must start again from step 1.\n",
    "\n",
    "- With persistence → you restart from step 3 or 4 (where you last saved).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97255bfe",
   "metadata": {},
   "source": [
    "# checkpointers in persistent\n",
    "Checkpointers are like “save points” in a workflow.\n",
    "\n",
    "- They store the state (data, inputs, outputs) of the workflow at specific moments.\n",
    "\n",
    "- Later, you can reload the workflow from that checkpoint.\n",
    "\n",
    "🔹 Example:\n",
    "Think of an online exam system:\n",
    "\n",
    "- Every 5 minutes, it autosaves your answers (checkpoints).\n",
    "\n",
    "- If your laptop shuts down, when you log back in, your answers up to the last save are still there.\n",
    "\n",
    "In LangGraph, checkpointers do the same thing for AI workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bfcc4",
   "metadata": {},
   "source": [
    "# Threads in persistent\n",
    "\n",
    "A thread is like a separate conversation or workflow instance that gets its own saved state.\n",
    "\n",
    "- Each thread has its own memory and checkpoints.\n",
    "\n",
    "- You can pause one thread and start another, then come back later.\n",
    "\n",
    "🔹 Example:\n",
    "Think of WhatsApp chats:\n",
    "\n",
    "- Each chat with a person is like a “thread.”\n",
    "\n",
    "- Messages are saved (persistent), so when you reopen the chat, you see the history.\n",
    "\n",
    "- Each conversation is independent of the others.\n",
    "\n",
    "In LangGraph, threads let you manage multiple workflows (conversations, tasks, or jobs) at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0df825",
   "metadata": {},
   "source": [
    "# benefits of Persistent\n",
    "- Short term Memory\n",
    "- Fault Tolerance\n",
    "- Human in the loop\n",
    "- Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2701b9a",
   "metadata": {},
   "source": [
    "# MemorySaver vs InMemorySaver\n",
    "- InMemorySaver → Very simple saver, keeps checkpoints only in RAM, lost when program ends. Good for quick testing.\n",
    "\n",
    "- MemorySaver → Higher-level saver that organizes checkpoints per thread for LangGraph workflows. Still in-memory, but structured for persistence during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0153f807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from typing import  Annotated,TypedDict\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6ea1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class state(TypedDict):\n",
    "    topic:str\n",
    "    joke:str\n",
    "    explain:str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ad87ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model='llama-3.1-8b-instant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dc63344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_gen(state:state):\n",
    "    prompt=f\"Generate the short joke on the foolowing topic :{state['topic']}\"\n",
    "    response=llm.invoke(prompt)\n",
    "    return {'joke':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2eadf032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_exp(state:state):\n",
    "    prompt=f\"explain the following joke in urdu {state['topic']}\"\n",
    "    exp=llm.invoke(prompt)\n",
    "    return {'explain':exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49276690",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(state)\n",
    "graph.add_node('joke_gen',joke_gen)\n",
    "graph.add_node('joke_exp',joke_exp)\n",
    "\n",
    "graph.add_edge(START,'joke_gen')\n",
    "graph.add_edge('joke_gen','joke_exp')\n",
    "graph.add_edge('joke_exp',END)\n",
    "\n",
    "checkpointer=InMemorySaver()\n",
    "chatbot=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ca10aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae1e86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'configurable':{'thread_id':thread_id}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'pizza'},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce0dca8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016608481, 'prompt_time': 0.005815748, 'queue_time': 0.090975112, 'total_time': 0.022424229}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9a162ff8-f8c6-432b-a42e-74563bee7c01-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}),\n",
       " 'explain': AIMessage(content='یہ جملہ ایک جوک ہے جس میں ایک شخص نے ایک پیتزا کے بارے میں کہا ہے۔\\n\\n\"پیتزا\"\\n\\nاس جملے کا مطلب ہے \"پیتزا\" ہی جس کا حوالہ دیتا ہے۔ یہ ایک ایسی بات ہے جو صرف \"پیتزا\" کا ذکر کرتی ہے، جیسے کہ ایک شخص کے بھاگ جانے کی وجہ \"پیتزا\" ہو۔\\n\\nیہ جوک اس بات پر مبنی ہے کہ پیتزا ایک ایسا کھانا ہے جس کا ذکر کرنا بہت آسان ہے، لیکن جب کوئی شخص کہتا ہے \"پیتزا\" تو ہم سمجھتے ہیں کہ وہ کچھ اور بھی کہنا چاہتا ہے۔', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 287, 'prompt_tokens': 43, 'total_tokens': 330, 'completion_time': 0.4217494, 'prompt_time': 0.015746508, 'queue_time': 0.093942462, 'total_time': 0.437495908}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--fea89cb4-9b54-4245-9875-902dc65282b9-0', usage_metadata={'input_tokens': 43, 'output_tokens': 287, 'total_tokens': 330})}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74008b2a",
   "metadata": {},
   "source": [
    "# Fault tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e644306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_gen1(state:state):\n",
    "    prompt=f\"Generate the short joke on the foolowing topic :{state['topic']}\"\n",
    "    response=llm.invoke(prompt)\n",
    "    print('Generation completed...')\n",
    "    return {'joke':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7f8e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # let llm take time to resposne so we can interrupt our  system for trying fault tolerance\n",
    "def joke_exp1(state:state):\n",
    "    prompt=f\"explain the following joke in urdu {state['topic']}\"\n",
    "    time.sleep(10)\n",
    "    exp=llm.invoke(prompt)\n",
    "    print('Explanation completed...')\n",
    "\n",
    "    return {'explain':exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c0f6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(state)\n",
    "graph.add_node('joke_gen1',joke_gen1)\n",
    "graph.add_node('joke_exp1',joke_exp1)\n",
    "\n",
    "graph.add_edge(START,'joke_gen1')\n",
    "graph.add_edge('joke_gen1','joke_exp1')\n",
    "graph.add_edge('joke_exp1',END)\n",
    "\n",
    "checkpointer=InMemorySaver()\n",
    "chatbot=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d257f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id_n='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4d51ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation completed...\n",
      "Explanation completed...\n"
     ]
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'pizza'},\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "791f5d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}),\n",
       " 'explain': AIMessage(content='یہ جوک یہ ہے:\\n\\nپیزا\\n\\nان کی وضاحت یہ ہے:\\n\\nایک شخص نے اپنے دوست کو پہنچایا اور کہا، \"آج تو میرے لیے ہی پیزا لائی ہوں، لیکن میں نے سوچا ہے کہ تو بھی پیزا کھانا چاہے ہو گا۔\"\\n\\nاس کے دوست نے پوچھا، \"کیا تو ہے؟ میں نے تو پہلے ہی کہا تھا کہ مجھے پیزا نہیں کھانے دے۔\"\\n\\nپہلے شخص نے کہا، \"ایسا ہی تو نہیں، تو نے کہا تھا میں بھی پیزا کھانا چاہتا ہوں۔\"\\n\\nاس کے دوست نے کہا، \"تو نے کیا کہا تھا؟\"\\n\\nپہلے شخص نے کہا، \"تو نے کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے دوست نے کہا، \"ارے بھائی، میں نے کبھی پیزا کھانے کا اعلان نہیں کیا تھا۔ میں نے تو کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے بعد، پہلے شخص نے کہا، \"ارے بھائی، تو نے مجھے اپنا نام دیا ہے۔\"\\n\\nاس کے دوست نے کہا، \"کیا تو نے مجھے اپنا نام نہیں دیا تھا؟\"\\n\\nپہلے شخص نے کہا، \"جی ہاں تو نے مجھے مجھے اپنا نام دیا ہے، پیزا۔\"\\n\\nیہ جوک یہ ہے کہ جب دوسرے شخص نے کہا کہ \"پیزا کھائیں گے\" تو اس کے معنی میں \"آپ کا نام\" کہے گئے۔', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ff617da",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    None,\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f45a4737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='یہ جوک یہ ہے:\\n\\nپیزا\\n\\nان کی وضاحت یہ ہے:\\n\\nایک شخص نے اپنے دوست کو پہنچایا اور کہا، \"آج تو میرے لیے ہی پیزا لائی ہوں، لیکن میں نے سوچا ہے کہ تو بھی پیزا کھانا چاہے ہو گا۔\"\\n\\nاس کے دوست نے پوچھا، \"کیا تو ہے؟ میں نے تو پہلے ہی کہا تھا کہ مجھے پیزا نہیں کھانے دے۔\"\\n\\nپہلے شخص نے کہا، \"ایسا ہی تو نہیں، تو نے کہا تھا میں بھی پیزا کھانا چاہتا ہوں۔\"\\n\\nاس کے دوست نے کہا، \"تو نے کیا کہا تھا؟\"\\n\\nپہلے شخص نے کہا، \"تو نے کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے دوست نے کہا، \"ارے بھائی، میں نے کبھی پیزا کھانے کا اعلان نہیں کیا تھا۔ میں نے تو کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے بعد، پہلے شخص نے کہا، \"ارے بھائی، تو نے مجھے اپنا نام دیا ہے۔\"\\n\\nاس کے دوست نے کہا، \"کیا تو نے مجھے اپنا نام نہیں دیا تھا؟\"\\n\\nپہلے شخص نے کہا، \"جی ہاں تو نے مجھے مجھے اپنا نام دیا ہے، پیزا۔\"\\n\\nیہ جوک یہ ہے کہ جب دوسرے شخص نے کہا کہ \"پیزا کھائیں گے\" تو اس کے معنی میں \"آپ کا نام\" کہے گئے۔', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c36b-6eda-8002-6c91add157e9'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T20:24:00.216627+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4e3e-6a5a-8001-2547abe51d3c'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4e3e-6a5a-8001-2547abe51d3c'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T20:23:47.929740+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a3a-6738-8000-def77a234269'}}, tasks=(PregelTask(id='6e8d07df-662b-c158-c14e-c2373b21ec3e', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='یہ جوک یہ ہے:\\n\\nپیزا\\n\\nان کی وضاحت یہ ہے:\\n\\nایک شخص نے اپنے دوست کو پہنچایا اور کہا، \"آج تو میرے لیے ہی پیزا لائی ہوں، لیکن میں نے سوچا ہے کہ تو بھی پیزا کھانا چاہے ہو گا۔\"\\n\\nاس کے دوست نے پوچھا، \"کیا تو ہے؟ میں نے تو پہلے ہی کہا تھا کہ مجھے پیزا نہیں کھانے دے۔\"\\n\\nپہلے شخص نے کہا، \"ایسا ہی تو نہیں، تو نے کہا تھا میں بھی پیزا کھانا چاہتا ہوں۔\"\\n\\nاس کے دوست نے کہا، \"تو نے کیا کہا تھا؟\"\\n\\nپہلے شخص نے کہا، \"تو نے کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے دوست نے کہا، \"ارے بھائی، میں نے کبھی پیزا کھانے کا اعلان نہیں کیا تھا۔ میں نے تو کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے بعد، پہلے شخص نے کہا، \"ارے بھائی، تو نے مجھے اپنا نام دیا ہے۔\"\\n\\nاس کے دوست نے کہا، \"کیا تو نے مجھے اپنا نام نہیں دیا تھا؟\"\\n\\nپہلے شخص نے کہا، \"جی ہاں تو نے مجھے مجھے اپنا نام دیا ہے، پیزا۔\"\\n\\nیہ جوک یہ ہے کہ جب دوسرے شخص نے کہا کہ \"پیزا کھائیں گے\" تو اس کے معنی میں \"آپ کا نام\" کہے گئے۔', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a3a-6738-8000-def77a234269'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:23:47.508602+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a38-66e1-bfff-11cf76741ec8'}}, tasks=(PregelTask(id='8aaa9cd6-4e7c-0ddc-9aad-8cae1b53133f', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a38-66e1-bfff-11cf76741ec8'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T20:23:47.507781+00:00', parent_config=None, tasks=(PregelTask(id='bf4660b1-f56b-cc2f-622e-b1022a55a932', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chatbot.get_state_history(config=config2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7274c95d",
   "metadata": {},
   "source": [
    "# Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62e883f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation completed...\n",
      "Explanation completed...\n"
     ]
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'burger'},\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93a061ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why was the burger in a bad mood? \\n\\nBecause it had a beef with everything.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 46, 'total_tokens': 65, 'completion_time': 0.027816835, 'prompt_time': 0.093438171, 'queue_time': 0.249228309, 'total_time': 0.121255006}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--059d69f8-5cf2-4344-a35a-ab8b79d87772-0', usage_metadata={'input_tokens': 46, 'output_tokens': 19, 'total_tokens': 65}), 'explain': AIMessage(content='Kuchh zameen se zyada nahin hai, lekin burger nahin bhi hai. (Kuchh zameen se zyada nahin hai) ishara hai kisi cheez ki, aur (burger nahin bhi hai) ishara hai kisi cheez ki jise burger kehte hain, lekin yeh kuchh zameen se zyada nahin hai. \\n\\nIs joke ki maanani, yeh ek burger hai jo kisi zameen se adhik nahin hai, magar yeh burger hai jisne ek zameen se adhik zameen ko apne pass kar liya hai, aur yeh zameen uske pas hai, lekin yeh burger wahi hai, jo kisi zameen se adhik nahin hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 183, 'prompt_tokens': 43, 'total_tokens': 226, 'completion_time': 0.360558966, 'prompt_time': 0.05391899, 'queue_time': 0.104946539, 'total_time': 0.414477956}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d0c8d0a1-db07-428b-8974-6c71c0f0d479-0', usage_metadata={'input_tokens': 43, 'output_tokens': 183, 'total_tokens': 226})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f7-3162-6742-8006-5e849cffb5c2'}}, metadata={'source': 'loop', 'step': 6, 'parents': {}}, created_at='2025-09-06T20:24:11.747080+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c8ec-6402-8005-7826ae8c8d00'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why was the burger in a bad mood? \\n\\nBecause it had a beef with everything.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 46, 'total_tokens': 65, 'completion_time': 0.027816835, 'prompt_time': 0.093438171, 'queue_time': 0.249228309, 'total_time': 0.121255006}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--059d69f8-5cf2-4344-a35a-ab8b79d87772-0', usage_metadata={'input_tokens': 46, 'output_tokens': 19, 'total_tokens': 65}), 'explain': AIMessage(content='یہ جوک یہ ہے:\\n\\nپیزا\\n\\nان کی وضاحت یہ ہے:\\n\\nایک شخص نے اپنے دوست کو پہنچایا اور کہا، \"آج تو میرے لیے ہی پیزا لائی ہوں، لیکن میں نے سوچا ہے کہ تو بھی پیزا کھانا چاہے ہو گا۔\"\\n\\nاس کے دوست نے پوچھا، \"کیا تو ہے؟ میں نے تو پہلے ہی کہا تھا کہ مجھے پیزا نہیں کھانے دے۔\"\\n\\nپہلے شخص نے کہا، \"ایسا ہی تو نہیں، تو نے کہا تھا میں بھی پیزا کھانا چاہتا ہوں۔\"\\n\\nاس کے دوست نے کہا، \"تو نے کیا کہا تھا؟\"\\n\\nپہلے شخص نے کہا، \"تو نے کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے دوست نے کہا، \"ارے بھائی، میں نے کبھی پیزا کھانے کا اعلان نہیں کیا تھا۔ میں نے تو کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے بعد، پہلے شخص نے کہا، \"ارے بھائی، تو نے مجھے اپنا نام دیا ہے۔\"\\n\\nاس کے دوست نے کہا، \"کیا تو نے مجھے اپنا نام نہیں دیا تھا؟\"\\n\\nپہلے شخص نے کہا، \"جی ہاں تو نے مجھے مجھے اپنا نام دیا ہے، پیزا۔\"\\n\\nیہ جوک یہ ہے کہ جب دوسرے شخص نے کہا کہ \"پیزا کھائیں گے\" تو اس کے معنی میں \"آپ کا نام\" کہے گئے۔', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c8ec-6402-8005-7826ae8c8d00'}}, metadata={'source': 'loop', 'step': 5, 'parents': {}}, created_at='2025-09-06T20:24:00.793475+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c3af-62b1-8004-a8dc12753a75'}}, tasks=(PregelTask(id='60620d32-202a-70bd-8985-ed1a8bb4725a', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Kuchh zameen se zyada nahin hai, lekin burger nahin bhi hai. (Kuchh zameen se zyada nahin hai) ishara hai kisi cheez ki, aur (burger nahin bhi hai) ishara hai kisi cheez ki jise burger kehte hain, lekin yeh kuchh zameen se zyada nahin hai. \\n\\nIs joke ki maanani, yeh ek burger hai jo kisi zameen se adhik nahin hai, magar yeh burger hai jisne ek zameen se adhik zameen ko apne pass kar liya hai, aur yeh zameen uske pas hai, lekin yeh burger wahi hai, jo kisi zameen se adhik nahin hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 183, 'prompt_tokens': 43, 'total_tokens': 226, 'completion_time': 0.360558966, 'prompt_time': 0.05391899, 'queue_time': 0.104946539, 'total_time': 0.414477956}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d0c8d0a1-db07-428b-8974-6c71c0f0d479-0', usage_metadata={'input_tokens': 43, 'output_tokens': 183, 'total_tokens': 226})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='یہ جوک یہ ہے:\\n\\nپیزا\\n\\nان کی وضاحت یہ ہے:\\n\\nایک شخص نے اپنے دوست کو پہنچایا اور کہا، \"آج تو میرے لیے ہی پیزا لائی ہوں، لیکن میں نے سوچا ہے کہ تو بھی پیزا کھانا چاہے ہو گا۔\"\\n\\nاس کے دوست نے پوچھا، \"کیا تو ہے؟ میں نے تو پہلے ہی کہا تھا کہ مجھے پیزا نہیں کھانے دے۔\"\\n\\nپہلے شخص نے کہا، \"ایسا ہی تو نہیں، تو نے کہا تھا میں بھی پیزا کھانا چاہتا ہوں۔\"\\n\\nاس کے دوست نے کہا، \"تو نے کیا کہا تھا؟\"\\n\\nپہلے شخص نے کہا، \"تو نے کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے دوست نے کہا، \"ارے بھائی، میں نے کبھی پیزا کھانے کا اعلان نہیں کیا تھا۔ میں نے تو کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے بعد، پہلے شخص نے کہا، \"ارے بھائی، تو نے مجھے اپنا نام دیا ہے۔\"\\n\\nاس کے دوست نے کہا، \"کیا تو نے مجھے اپنا نام نہیں دیا تھا؟\"\\n\\nپہلے شخص نے کہا، \"جی ہاں تو نے مجھے مجھے اپنا نام دیا ہے، پیزا۔\"\\n\\nیہ جوک یہ ہے کہ جب دوسرے شخص نے کہا کہ \"پیزا کھائیں گے\" تو اس کے معنی میں \"آپ کا نام\" کہے گئے۔', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c3af-62b1-8004-a8dc12753a75'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-09-06T20:24:00.244182+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c3ad-6bbf-8003-549157335226'}}, tasks=(PregelTask(id='ffb20ec9-fd39-c70c-2a72-f9d1015debe2', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the burger in a bad mood? \\n\\nBecause it had a beef with everything.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 46, 'total_tokens': 65, 'completion_time': 0.027816835, 'prompt_time': 0.093438171, 'queue_time': 0.249228309, 'total_time': 0.121255006}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--059d69f8-5cf2-4344-a35a-ab8b79d87772-0', usage_metadata={'input_tokens': 46, 'output_tokens': 19, 'total_tokens': 65})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='یہ جوک یہ ہے:\\n\\nپیزا\\n\\nان کی وضاحت یہ ہے:\\n\\nایک شخص نے اپنے دوست کو پہنچایا اور کہا، \"آج تو میرے لیے ہی پیزا لائی ہوں، لیکن میں نے سوچا ہے کہ تو بھی پیزا کھانا چاہے ہو گا۔\"\\n\\nاس کے دوست نے پوچھا، \"کیا تو ہے؟ میں نے تو پہلے ہی کہا تھا کہ مجھے پیزا نہیں کھانے دے۔\"\\n\\nپہلے شخص نے کہا، \"ایسا ہی تو نہیں، تو نے کہا تھا میں بھی پیزا کھانا چاہتا ہوں۔\"\\n\\nاس کے دوست نے کہا، \"تو نے کیا کہا تھا؟\"\\n\\nپہلے شخص نے کہا، \"تو نے کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے دوست نے کہا، \"ارے بھائی، میں نے کبھی پیزا کھانے کا اعلان نہیں کیا تھا۔ میں نے تو کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے بعد، پہلے شخص نے کہا، \"ارے بھائی، تو نے مجھے اپنا نام دیا ہے۔\"\\n\\nاس کے دوست نے کہا، \"کیا تو نے مجھے اپنا نام نہیں دیا تھا؟\"\\n\\nپہلے شخص نے کہا، \"جی ہاں تو نے مجھے مجھے اپنا نام دیا ہے، پیزا۔\"\\n\\nیہ جوک یہ ہے کہ جب دوسرے شخص نے کہا کہ \"پیزا کھائیں گے\" تو اس کے معنی میں \"آپ کا نام\" کہے گئے۔', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c3ad-6bbf-8003-549157335226'}}, metadata={'source': 'input', 'step': 3, 'parents': {}}, created_at='2025-09-06T20:24:00.243594+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c36b-6eda-8002-6c91add157e9'}}, tasks=(PregelTask(id='1cc35dee-f80b-103b-14bb-132f66c66400', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'burger'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='یہ جوک یہ ہے:\\n\\nپیزا\\n\\nان کی وضاحت یہ ہے:\\n\\nایک شخص نے اپنے دوست کو پہنچایا اور کہا، \"آج تو میرے لیے ہی پیزا لائی ہوں، لیکن میں نے سوچا ہے کہ تو بھی پیزا کھانا چاہے ہو گا۔\"\\n\\nاس کے دوست نے پوچھا، \"کیا تو ہے؟ میں نے تو پہلے ہی کہا تھا کہ مجھے پیزا نہیں کھانے دے۔\"\\n\\nپہلے شخص نے کہا، \"ایسا ہی تو نہیں، تو نے کہا تھا میں بھی پیزا کھانا چاہتا ہوں۔\"\\n\\nاس کے دوست نے کہا، \"تو نے کیا کہا تھا؟\"\\n\\nپہلے شخص نے کہا، \"تو نے کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے دوست نے کہا، \"ارے بھائی، میں نے کبھی پیزا کھانے کا اعلان نہیں کیا تھا۔ میں نے تو کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے بعد، پہلے شخص نے کہا، \"ارے بھائی، تو نے مجھے اپنا نام دیا ہے۔\"\\n\\nاس کے دوست نے کہا، \"کیا تو نے مجھے اپنا نام نہیں دیا تھا؟\"\\n\\nپہلے شخص نے کہا، \"جی ہاں تو نے مجھے مجھے اپنا نام دیا ہے، پیزا۔\"\\n\\nیہ جوک یہ ہے کہ جب دوسرے شخص نے کہا کہ \"پیزا کھائیں گے\" تو اس کے معنی میں \"آپ کا نام\" کہے گئے۔', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-c36b-6eda-8002-6c91add157e9'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T20:24:00.216627+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4e3e-6a5a-8001-2547abe51d3c'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4e3e-6a5a-8001-2547abe51d3c'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T20:23:47.929740+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a3a-6738-8000-def77a234269'}}, tasks=(PregelTask(id='6e8d07df-662b-c158-c14e-c2373b21ec3e', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='یہ جوک یہ ہے:\\n\\nپیزا\\n\\nان کی وضاحت یہ ہے:\\n\\nایک شخص نے اپنے دوست کو پہنچایا اور کہا، \"آج تو میرے لیے ہی پیزا لائی ہوں، لیکن میں نے سوچا ہے کہ تو بھی پیزا کھانا چاہے ہو گا۔\"\\n\\nاس کے دوست نے پوچھا، \"کیا تو ہے؟ میں نے تو پہلے ہی کہا تھا کہ مجھے پیزا نہیں کھانے دے۔\"\\n\\nپہلے شخص نے کہا، \"ایسا ہی تو نہیں، تو نے کہا تھا میں بھی پیزا کھانا چاہتا ہوں۔\"\\n\\nاس کے دوست نے کہا، \"تو نے کیا کہا تھا؟\"\\n\\nپہلے شخص نے کہا، \"تو نے کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے دوست نے کہا، \"ارے بھائی، میں نے کبھی پیزا کھانے کا اعلان نہیں کیا تھا۔ میں نے تو کہا تھا پیزا کھائیں گے۔\"\\n\\nاس کے بعد، پہلے شخص نے کہا، \"ارے بھائی، تو نے مجھے اپنا نام دیا ہے۔\"\\n\\nاس کے دوست نے کہا، \"کیا تو نے مجھے اپنا نام نہیں دیا تھا؟\"\\n\\nپہلے شخص نے کہا، \"جی ہاں تو نے مجھے مجھے اپنا نام دیا ہے، پیزا۔\"\\n\\nیہ جوک یہ ہے کہ جب دوسرے شخص نے کہا کہ \"پیزا کھائیں گے\" تو اس کے معنی میں \"آپ کا نام\" کہے گئے۔', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 643, 'prompt_tokens': 43, 'total_tokens': 686, 'completion_time': 1.160808373, 'prompt_time': 0.005882471, 'queue_time': 0.084624379, 'total_time': 1.1666908440000001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ad9a53fc-bd5f-4cdc-b32e-93e81b22643b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 643, 'total_tokens': 686})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a3a-6738-8000-def77a234269'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:23:47.508602+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a38-66e1-bfff-11cf76741ec8'}}, tasks=(PregelTask(id='8aaa9cd6-4e7c-0ddc-9aad-8cae1b53133f', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.015446919, 'prompt_time': 0.059389952, 'queue_time': 0.158662008, 'total_time': 0.074836871}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7614331d-2b4c-4849-969c-c9688a115c78-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f6-4a38-66e1-bfff-11cf76741ec8'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T20:23:47.507781+00:00', parent_config=None, tasks=(PregelTask(id='bf4660b1-f56b-cc2f-622e-b1022a55a932', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chatbot.get_state_history(config=config2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f3ea65",
   "metadata": {},
   "source": [
    "# persistent in langgraph\n",
    "Persistence in LangGraph means saving the memory and state of your AI workflow (graph) so it doesn’t get lost when something goes wrong or when you want to resume later.\n",
    "\n",
    "Think of it like a save game feature in a video game.\n",
    "\n",
    "- Without persistence → if the game crashes, you lose progress.\n",
    "\n",
    "- With persistence → you reload from the last checkpoint.\n",
    "\n",
    "So in LangGraph, persistence allows your workflow to survive crashes, restarts, or interruptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939fe3c",
   "metadata": {},
   "source": [
    "# Fault tolerance\n",
    "Fault tolerance means the system can recover from errors without starting everything from scratch.\n",
    "\n",
    "Persistence helps by:\n",
    "\n",
    "- Saving progress at certain steps (checkpoints).\n",
    "\n",
    "- If an error or crash happens, the graph reloads from the last checkpoint instead of starting at the beginning.\n",
    "\n",
    "- This makes the system more reliable and faster because you don’t redo completed steps.\n",
    "\n",
    "🔹 Example:\n",
    "Imagine you are building a workflow that processes a customer’s request in 5 steps:\n",
    "\n",
    "- Validate user input\n",
    "\n",
    "- Retrieve information from a database\n",
    "\n",
    "- Summarize the data\n",
    "\n",
    "- Generate a response\n",
    "\n",
    "- Send it back to the user\n",
    "\n",
    "If the system crashes at step 4:\n",
    "\n",
    "- Without persistence → you must start again from step 1.\n",
    "\n",
    "- With persistence → you restart from step 3 or 4 (where you last saved).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7d52a",
   "metadata": {},
   "source": [
    "# checkpointers in persistent\n",
    "Checkpointers are like “save points” in a workflow.\n",
    "\n",
    "- They store the state (data, inputs, outputs) of the workflow at specific moments.\n",
    "\n",
    "- Later, you can reload the workflow from that checkpoint.\n",
    "\n",
    "🔹 Example:\n",
    "Think of an online exam system:\n",
    "\n",
    "- Every 5 minutes, it autosaves your answers (checkpoints).\n",
    "\n",
    "- If your laptop shuts down, when you log back in, your answers up to the last save are still there.\n",
    "\n",
    "In LangGraph, checkpointers do the same thing for AI workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de1692",
   "metadata": {},
   "source": [
    "# Threads in persistent\n",
    "\n",
    "A thread is like a separate conversation or workflow instance that gets its own saved state.\n",
    "\n",
    "- Each thread has its own memory and checkpoints.\n",
    "\n",
    "- You can pause one thread and start another, then come back later.\n",
    "\n",
    "🔹 Example:\n",
    "Think of WhatsApp chats:\n",
    "\n",
    "- Each chat with a person is like a “thread.”\n",
    "\n",
    "- Messages are saved (persistent), so when you reopen the chat, you see the history.\n",
    "\n",
    "- Each conversation is independent of the others.\n",
    "\n",
    "In LangGraph, threads let you manage multiple workflows (conversations, tasks, or jobs) at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2328b",
   "metadata": {},
   "source": [
    "# benefits of Persistent\n",
    "- Short term Memory\n",
    "- Fault Tolerance\n",
    "- Human in the loop\n",
    "- Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21454155",
   "metadata": {},
   "source": [
    "# MemorySaver vs InMemorySaver\n",
    "- InMemorySaver → Very simple saver, keeps checkpoints only in RAM, lost when program ends. Good for quick testing.\n",
    "\n",
    "- MemorySaver → Higher-level saver that organizes checkpoints per thread for LangGraph workflows. Still in-memory, but structured for persistence during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e13759a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from typing import  Annotated,TypedDict\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d776f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class state(TypedDict):\n",
    "    topic:str\n",
    "    joke:str\n",
    "    explain:str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a53f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model='llama-3.1-8b-instant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f6a8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_gen(state:state):\n",
    "    prompt=f\"Generate the short joke on the foolowing topic :{state['topic']}\"\n",
    "    response=llm.invoke(prompt)\n",
    "    return {'joke':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a18e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_exp(state:state):\n",
    "    prompt=f\"explain the following joke in urdu {state['topic']}\"\n",
    "    exp=llm.invoke(prompt)\n",
    "    return {'explain':exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b560e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(state)\n",
    "graph.add_node('joke_gen',joke_gen)\n",
    "graph.add_node('joke_exp',joke_exp)\n",
    "\n",
    "graph.add_edge(START,'joke_gen')\n",
    "graph.add_edge('joke_gen','joke_exp')\n",
    "graph.add_edge('joke_exp',END)\n",
    "\n",
    "checkpointer=InMemorySaver()\n",
    "chatbot=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae4c5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0e27f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'configurable':{'thread_id':thread_id}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'pizza'},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "473c0f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}),\n",
       " 'explain': AIMessage(content='Pizza کا یہ جوک ہے:\\n\\n\" Pizza ایک خاتون سے پوچھا گیا کہ وہ کیا ہے۔ وہ کہنے لگی کہ میں ایک پیزا ہوں۔ پیزا نے کہا، \\'کیا آپ کے ماں باپ بھی پیزا ہیں؟\\' خاتون نے کہا، \\'ہاں، وہ بھی پیزا ہیں۔\\' پیزا نے کہا، \\'تو آپ کے ڈیڈی کا داڑھی کہاں ہے؟\\' خاتون نے کہا، \\'وہ میرے سر کے اوپر ہیں۔\\' پیزا نے کہا، \\'تو آپ کے باپ کا داڑھی کہاں ہے؟\\' خاتون نے کہا، \\'وہ میرے سر کے اوپر ہیں۔\\' پیزا نے کہا، \\'تو یہ آپ کی ماں باپ ہیں؟\\' خاتون نے کہا، \\'ہاں، یہ میں ہی ہوں۔\\'\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 43, 'total_tokens': 414, 'completion_time': 0.494079589, 'prompt_time': 0.030879016, 'queue_time': 0.129438743, 'total_time': 0.524958605}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b2de9c0-85d6-42f8-881a-4539bff92076-0', usage_metadata={'input_tokens': 43, 'output_tokens': 371, 'total_tokens': 414})}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8f1121",
   "metadata": {},
   "source": [
    "# Fault tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ca191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_gen1(state:state):\n",
    "    prompt=f\"Generate the short joke on the foolowing topic :{state['topic']}\"\n",
    "    response=llm.invoke(prompt)\n",
    "    print('Generation completed...')\n",
    "    return {'joke':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62165a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # let llm take time to resposne so we can interrupt our  system for trying fault tolerance\n",
    "def joke_exp1(state:state):\n",
    "    prompt=f\"explain the following joke in urdu {state['topic']}\"\n",
    "    time.sleep(10)\n",
    "    exp=llm.invoke(prompt)\n",
    "    print('Explanation completed...')\n",
    "\n",
    "    return {'explain':exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d97b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(state)\n",
    "graph.add_node('joke_gen1',joke_gen1)\n",
    "graph.add_node('joke_exp1',joke_exp1)\n",
    "\n",
    "graph.add_edge(START,'joke_gen1')\n",
    "graph.add_edge('joke_gen1','joke_exp1')\n",
    "graph.add_edge('joke_exp1',END)\n",
    "\n",
    "checkpointer=InMemorySaver()\n",
    "chatbot=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8891112",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id_n='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b64fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation completed...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 2\u001b[39m\n",
      "\u001b[32m      1\u001b[39m config2={\u001b[33m'\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m'\u001b[39m:{\u001b[33m'\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m'\u001b[39m:thread_id_n}}\n",
      "\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result=\u001b[43mchatbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpizza\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig2\u001b[49m\n",
      "\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n",
      "\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n",
      "\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n",
      "\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n",
      "\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n",
      "\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n",
      "\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n",
      "\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n",
      "\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n",
      "\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n",
      "\u001b[32m     40\u001b[39m     task.writes.clear()\n",
      "\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n",
      "\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n",
      "\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Langgraph_Learning\\langgraph_env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n",
      "\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n",
      "\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n",
      "\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mjoke_exp1\u001b[39m\u001b[34m(state)\u001b[39m\n",
      "\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjoke_exp1\u001b[39m(state:state):\n",
      "\u001b[32m      3\u001b[39m     prompt=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexplain the following joke in urdu \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m'\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m      5\u001b[39m     exp=llm.invoke(prompt)\n",
      "\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mExplanation completed...\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'pizza'},\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d73ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016743983, 'prompt_time': 0.005746572, 'queue_time': 0.048494358, 'total_time': 0.022490555}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f941491b-1c03-48ef-9578-2cf1f92f58b3-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}),\n",
       " 'explain': AIMessage(content='Koi joke hai: Pizza\\n\\nYeh joke yeh hai: koi pizza parlor hai jahan par ek customer aata hai aur order karta hai: \"Maine apne dost ko pizza khaane ke liye kaha hai, lekin wo pizza kheena nahin khata. Main apne dost ko pizza khaane ke liye bolun, lekin use pizza kheena nahin khana hai.\"\\n\\nPizza parlor owner bolta hai: \"Aapko kya problem hai? Maine aapke dost ko pizza kheena nahin khaana hai.\"\\n\\nCustomer bolta hai: \"Arre, main usko pizza kheena nahin khana hai, main usko khana hai, lekin usse pizza kheena nahin khana hai.\"\\n\\nYeh joke ek akhbari shaili mehsoos hota hai, jahan par ek customer usse keh raha hai ki uska dost pizza kheena nahin khata, lekin uska dost usse keh raha hai ki woh khana nahin khata, balki woh pizza kheena khana nahin chahta. Yeh joke ek akarshak aur majedar joke hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 265, 'prompt_tokens': 43, 'total_tokens': 308, 'completion_time': 0.502257352, 'prompt_time': 0.005772792, 'queue_time': 0.048120317, 'total_time': 0.508030144}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--99ada6d7-e99d-43ff-a9eb-d7d0df3f1e02-0', usage_metadata={'input_tokens': 43, 'output_tokens': 265, 'total_tokens': 308})}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe236a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation completed...\n"
     ]
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    None,\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13c057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T15:52:25.846489+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-ecca-63a1-8001-fcf36c54577b'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-ecca-63a1-8001-fcf36c54577b'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T15:34:36.780413+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e354-62c0-8000-09640931bb8d'}}, tasks=(PregelTask(id='61d7e66b-c5b3-eb25-0a51-8a638d7af224', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e354-62c0-8000-09640931bb8d'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T15:34:35.788352+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e352-6e90-bfff-e6c7952562fd'}}, tasks=(PregelTask(id='290746e0-7676-e7e0-e56d-a22cdbd9b7f2', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e352-6e90-bfff-e6c7952562fd'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T15:34:35.787833+00:00', parent_config=None, tasks=(PregelTask(id='9bd735fb-22ed-9dd6-2dbd-ff3dbda3d861', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list(chatbot.get_state_history(config=config2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d71a2",
   "metadata": {},
   "source": [
    "# Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d07490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation completed...\n",
      "Explanation completed...\n"
     ]
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n}}\n",
    "result=chatbot.invoke(\n",
    "    {'topic':'burger'},\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=list(chatbot.get_state_history(config=config2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8c08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why did the burger go to therapy? \\n\\nBecause it was feeling a little crumby.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.018759797, 'prompt_time': 0.10406644, 'queue_time': 0.06509964, 'total_time': 0.122826237}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--844c251c-aedd-42fe-9c41-29da55b480f6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Main ne ek burger ko pehli bar dekha tha aur usne mere se poocha, \"Kya tum mujhe khatam kar sakte ho?\"\\n\\nMain ne kehna shuru kiya, \"Kuch hi karunga, main aapko khatam to kar sakta hoon, lekin aapko khaane mein behter lagta hai.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 43, 'total_tokens': 125, 'completion_time': 0.214847333, 'prompt_time': 0.043010094, 'queue_time': 0.055033355, 'total_time': 0.257857427}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--757c9bd5-02a7-44b3-a222-64a1258853a6-0', usage_metadata={'input_tokens': 43, 'output_tokens': 82, 'total_tokens': 125})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-92ef-6c7f-8006-fc5aeae87213'}}, metadata={'source': 'loop', 'step': 6, 'parents': {}}, created_at='2025-09-06T15:55:02.161687+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-2841-66b8-8005-45cbc0103953'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why did the burger go to therapy? \\n\\nBecause it was feeling a little crumby.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.018759797, 'prompt_time': 0.10406644, 'queue_time': 0.06509964, 'total_time': 0.122826237}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--844c251c-aedd-42fe-9c41-29da55b480f6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-2841-66b8-8005-45cbc0103953'}}, metadata={'source': 'loop', 'step': 5, 'parents': {}}, created_at='2025-09-06T15:54:50.975384+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f88-6f55-8004-f7a50feb3c58'}}, tasks=(PregelTask(id='b5e51c1f-2554-1f4b-7731-23a0d37cada4', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Main ne ek burger ko pehli bar dekha tha aur usne mere se poocha, \"Kya tum mujhe khatam kar sakte ho?\"\\n\\nMain ne kehna shuru kiya, \"Kuch hi karunga, main aapko khatam to kar sakta hoon, lekin aapko khaane mein behter lagta hai.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 43, 'total_tokens': 125, 'completion_time': 0.214847333, 'prompt_time': 0.043010094, 'queue_time': 0.055033355, 'total_time': 0.257857427}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--757c9bd5-02a7-44b3-a222-64a1258853a6-0', usage_metadata={'input_tokens': 43, 'output_tokens': 82, 'total_tokens': 125})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'burger', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f88-6f55-8004-f7a50feb3c58'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-09-06T15:54:50.060979+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f87-6a3c-8003-2954195c3dcc'}}, tasks=(PregelTask(id='5d4e98a3-1677-fe3f-e076-7cfcca706710', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the burger go to therapy? \\n\\nBecause it was feeling a little crumby.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.018759797, 'prompt_time': 0.10406644, 'queue_time': 0.06509964, 'total_time': 0.122826237}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--844c251c-aedd-42fe-9c41-29da55b480f6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f87-6a3c-8003-2954195c3dcc'}}, metadata={'source': 'input', 'step': 3, 'parents': {}}, created_at='2025-09-06T15:54:50.060437+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}}, tasks=(PregelTask(id='3e656e65-42e1-2c6c-907f-5e68811f95a7', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'burger'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T15:52:25.846489+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-ecca-63a1-8001-fcf36c54577b'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}, next=('joke_exp1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-ecca-63a1-8001-fcf36c54577b'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T15:34:36.780413+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e354-62c0-8000-09640931bb8d'}}, tasks=(PregelTask(id='61d7e66b-c5b3-eb25-0a51-8a638d7af224', name='joke_exp1', path=('__pregel_pull', 'joke_exp1'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen1',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e354-62c0-8000-09640931bb8d'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T15:34:35.788352+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e352-6e90-bfff-e6c7952562fd'}}, tasks=(PregelTask(id='290746e0-7676-e7e0-e56d-a22cdbd9b7f2', name='joke_gen1', path=('__pregel_pull', 'joke_gen1'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e352-6e90-bfff-e6c7952562fd'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T15:34:35.787833+00:00', parent_config=None, tasks=(PregelTask(id='9bd735fb-22ed-9dd6-2dbd-ff3dbda3d861', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a1596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-92ef-6c7f-8006-fc5aeae87213'}} {'topic': 'burger', 'joke': AIMessage(content='Why did the burger go to therapy? \\n\\nBecause it was feeling a little crumby.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.018759797, 'prompt_time': 0.10406644, 'queue_time': 0.06509964, 'total_time': 0.122826237}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--844c251c-aedd-42fe-9c41-29da55b480f6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Main ne ek burger ko pehli bar dekha tha aur usne mere se poocha, \"Kya tum mujhe khatam kar sakte ho?\"\\n\\nMain ne kehna shuru kiya, \"Kuch hi karunga, main aapko khatam to kar sakta hoon, lekin aapko khaane mein behter lagta hai.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 43, 'total_tokens': 125, 'completion_time': 0.214847333, 'prompt_time': 0.043010094, 'queue_time': 0.055033355, 'total_time': 0.257857427}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--757c9bd5-02a7-44b3-a222-64a1258853a6-0', usage_metadata={'input_tokens': 43, 'output_tokens': 82, 'total_tokens': 125})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-2841-66b8-8005-45cbc0103953'}} {'topic': 'burger', 'joke': AIMessage(content='Why did the burger go to therapy? \\n\\nBecause it was feeling a little crumby.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.018759797, 'prompt_time': 0.10406644, 'queue_time': 0.06509964, 'total_time': 0.122826237}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_2115512ff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--844c251c-aedd-42fe-9c41-29da55b480f6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f88-6f55-8004-f7a50feb3c58'}} {'topic': 'burger', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b39d-1f87-6a3c-8003-2954195c3dcc'}} {'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}} {'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}), 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-ecca-63a1-8001-fcf36c54577b'}} {'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66})}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e354-62c0-8000-09640931bb8d'}} {'topic': 'pizza'}\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f08b36f-e352-6e90-bfff-e6c7952562fd'}} {}\n"
     ]
    }
   ],
   "source": [
    "for i in history:\n",
    "    print(i.config,i.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f99c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2={'configurable':{'thread_id':thread_id_n,'checkpoint_id':'1f08b397-c032-6d17-8002-93219853b5ad'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ea31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 46, 'total_tokens': 66, 'completion_time': 0.016620453, 'prompt_time': 0.005892534, 'queue_time': 0.049852006, 'total_time': 0.022512987}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a56d55-6fb0-472e-b74e-5109d99afa62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 20, 'total_tokens': 66}),\n",
       " 'explain': AIMessage(content='Kuchh logon ko yeh joke pasand aati hai:\\n\\nPizza ki zuban ko kya kehte hain?\\n\\nJawab: Cheesy!\\n\\nYeh joke hai ek shabd khel jismein \"cheesy\" ka matlab hai kuchh cheez jo bahut hi aam aur pasandida hoti hai, lekin yeh shabdon ka istemaal aise kar diya gaya hai jaise yeh ek jhootha shabd ho. Ismein zuban ki cheez (pizza) ko cheezy kehna ek type of wordplay hai.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 43, 'total_tokens': 175, 'completion_time': 0.30479532, 'prompt_time': 0.006277031, 'queue_time': 0.049836708, 'total_time': 0.311072351}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--829ddabe-d3dc-468c-b465-f77d5fea9c60-0', usage_metadata={'input_tokens': 43, 'output_tokens': 132, 'total_tokens': 175})}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chatbot.invoke(None,config=config2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9195d85",
   "metadata": {},
   "source": [
    "# update state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2797082c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f08b607-050b-61ea-8000-c51873769598'}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.update_state(\n",
    "    config={\n",
    "        'configurable':{\n",
    "            'thread_id':'1',\n",
    "            'checkpoint_id':'1f08b397-c032-6d17-8002-93219853b5ad',\n",
    "            'checkpoint_ns':''\n",
    "            }\n",
    "            },\n",
    "                     values={'topic':'fries'}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b6d0c10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'fries'}, next=('joke_gen',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b607-050b-61ea-8000-c51873769598'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:31:16.594322+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}}, tasks=(PregelTask(id='37a89252-caa4-4d3c-f6ee-4d1f22a95ce8', name='joke_gen', path=('__pregel_pull', 'joke_gen'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='Pizza کا یہ جوک ہے:\\n\\n\" Pizza ایک خاتون سے پوچھا گیا کہ وہ کیا ہے۔ وہ کہنے لگی کہ میں ایک پیزا ہوں۔ پیزا نے کہا، \\'کیا آپ کے ماں باپ بھی پیزا ہیں؟\\' خاتون نے کہا، \\'ہاں، وہ بھی پیزا ہیں۔\\' پیزا نے کہا، \\'تو آپ کے ڈیڈی کا داڑھی کہاں ہے؟\\' خاتون نے کہا، \\'وہ میرے سر کے اوپر ہیں۔\\' پیزا نے کہا، \\'تو آپ کے باپ کا داڑھی کہاں ہے؟\\' خاتون نے کہا، \\'وہ میرے سر کے اوپر ہیں۔\\' پیزا نے کہا، \\'تو یہ آپ کی ماں باپ ہیں؟\\' خاتون نے کہا، \\'ہاں، یہ میں ہی ہوں۔\\'\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 43, 'total_tokens': 414, 'completion_time': 0.494079589, 'prompt_time': 0.030879016, 'queue_time': 0.129438743, 'total_time': 0.524958605}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b2de9c0-85d6-42f8-881a-4539bff92076-0', usage_metadata={'input_tokens': 43, 'output_tokens': 371, 'total_tokens': 414})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-8511-676b-8002-371af2ae002d'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T20:25:14.209047+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7cf8-617e-8001-051cb2c8452d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}, next=('joke_exp',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7cf8-617e-8001-051cb2c8452d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T20:25:13.359792+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7042-6fea-8000-03aeef0670aa'}}, tasks=(PregelTask(id='84a8ab59-da35-b15f-8f39-fcd939179d32', name='joke_exp', path=('__pregel_pull', 'joke_exp'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Pizza کا یہ جوک ہے:\\n\\n\" Pizza ایک خاتون سے پوچھا گیا کہ وہ کیا ہے۔ وہ کہنے لگی کہ میں ایک پیزا ہوں۔ پیزا نے کہا، \\'کیا آپ کے ماں باپ بھی پیزا ہیں؟\\' خاتون نے کہا، \\'ہاں، وہ بھی پیزا ہیں۔\\' پیزا نے کہا، \\'تو آپ کے ڈیڈی کا داڑھی کہاں ہے؟\\' خاتون نے کہا، \\'وہ میرے سر کے اوپر ہیں۔\\' پیزا نے کہا، \\'تو آپ کے باپ کا داڑھی کہاں ہے؟\\' خاتون نے کہا، \\'وہ میرے سر کے اوپر ہیں۔\\' پیزا نے کہا، \\'تو یہ آپ کی ماں باپ ہیں؟\\' خاتون نے کہا، \\'ہاں، یہ میں ہی ہوں۔\\'\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 43, 'total_tokens': 414, 'completion_time': 0.494079589, 'prompt_time': 0.030879016, 'queue_time': 0.129438743, 'total_time': 0.524958605}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b2de9c0-85d6-42f8-881a-4539bff92076-0', usage_metadata={'input_tokens': 43, 'output_tokens': 371, 'total_tokens': 414})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7042-6fea-8000-03aeef0670aa'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:25:12.027332+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7041-6bfd-bfff-fa05f68fecb5'}}, tasks=(PregelTask(id='52104c82-77f3-2dfc-214d-03bcf4bf9800', name='joke_gen', path=('__pregel_pull', 'joke_gen'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7041-6bfd-bfff-fa05f68fecb5'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T20:25:12.026824+00:00', parent_config=None, tasks=(PregelTask(id='a8c8bcc9-e509-4827-3d02-920637aea71d', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chatbot.get_state_history(config={'configurable':{'thread_id':'1'}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f39b0792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'fries',\n",
       " 'joke': AIMessage(content='Why did the fries go to therapy? \\n\\nBecause they were struggling to cope with the heat of the moment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 47, 'total_tokens': 70, 'completion_time': 0.042605748, 'prompt_time': 0.016848542, 'queue_time': 0.090819568, 'total_time': 0.05945429}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4a8b8990-a5ae-413e-b3bd-592a615b9f6f-0', usage_metadata={'input_tokens': 47, 'output_tokens': 23, 'total_tokens': 70}),\n",
       " 'explain': AIMessage(content='Main samajh nahi sakta ki kya joke diya gaya hai. Kya aap is joke ko explain karne ke liye ready hain?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 43, 'total_tokens': 79, 'completion_time': 0.068504242, 'prompt_time': 0.012168159, 'queue_time': 0.125282411, 'total_time': 0.080672401}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ce014bf-0a1a-470a-a07e-69f045be88f3-0', usage_metadata={'input_tokens': 43, 'output_tokens': 36, 'total_tokens': 79})}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(\n",
    "    None,config={\n",
    "        'configurable':{'thread_id':'1','checkpoint_id':'1f08b607-050b-61ea-8000-c51873769598'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f8f40175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'fries', 'joke': AIMessage(content='Why did the fries go to therapy? \\n\\nBecause they were struggling to cope with the heat of the moment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 47, 'total_tokens': 70, 'completion_time': 0.042605748, 'prompt_time': 0.016848542, 'queue_time': 0.090819568, 'total_time': 0.05945429}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4a8b8990-a5ae-413e-b3bd-592a615b9f6f-0', usage_metadata={'input_tokens': 47, 'output_tokens': 23, 'total_tokens': 70}), 'explain': AIMessage(content='Main samajh nahi sakta ki kya joke diya gaya hai. Kya aap is joke ko explain karne ke liye ready hain?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 43, 'total_tokens': 79, 'completion_time': 0.068504242, 'prompt_time': 0.012168159, 'queue_time': 0.125282411, 'total_time': 0.080672401}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ce014bf-0a1a-470a-a07e-69f045be88f3-0', usage_metadata={'input_tokens': 43, 'output_tokens': 36, 'total_tokens': 79})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b614-c696-6bf8-8002-9c1d6d7e21d5'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T20:37:25.855098+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b614-c2ed-61f9-8001-9678478201c7'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'fries', 'joke': AIMessage(content='Why did the fries go to therapy? \\n\\nBecause they were struggling to cope with the heat of the moment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 47, 'total_tokens': 70, 'completion_time': 0.042605748, 'prompt_time': 0.016848542, 'queue_time': 0.090819568, 'total_time': 0.05945429}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4a8b8990-a5ae-413e-b3bd-592a615b9f6f-0', usage_metadata={'input_tokens': 47, 'output_tokens': 23, 'total_tokens': 70})}, next=('joke_exp',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b614-c2ed-61f9-8001-9678478201c7'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T20:37:25.471038+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b607-050b-61ea-8000-c51873769598'}}, tasks=(PregelTask(id='176c9260-0cc7-959f-a5a8-e873b34f407b', name='joke_exp', path=('__pregel_pull', 'joke_exp'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Main samajh nahi sakta ki kya joke diya gaya hai. Kya aap is joke ko explain karne ke liye ready hain?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 43, 'total_tokens': 79, 'completion_time': 0.068504242, 'prompt_time': 0.012168159, 'queue_time': 0.125282411, 'total_time': 0.080672401}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ce014bf-0a1a-470a-a07e-69f045be88f3-0', usage_metadata={'input_tokens': 43, 'output_tokens': 36, 'total_tokens': 79})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'fries'}, next=('joke_gen',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b607-050b-61ea-8000-c51873769598'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:31:16.594322+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b397-c032-6d17-8002-93219853b5ad'}}, tasks=(PregelTask(id='37a89252-caa4-4d3c-f6ee-4d1f22a95ce8', name='joke_gen', path=('__pregel_pull', 'joke_gen'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the fries go to therapy? \\n\\nBecause they were struggling to cope with the heat of the moment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 47, 'total_tokens': 70, 'completion_time': 0.042605748, 'prompt_time': 0.016848542, 'queue_time': 0.090819568, 'total_time': 0.05945429}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4a8b8990-a5ae-413e-b3bd-592a615b9f6f-0', usage_metadata={'input_tokens': 47, 'output_tokens': 23, 'total_tokens': 70})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64}), 'explain': AIMessage(content='Pizza کا یہ جوک ہے:\\n\\n\" Pizza ایک خاتون سے پوچھا گیا کہ وہ کیا ہے۔ وہ کہنے لگی کہ میں ایک پیزا ہوں۔ پیزا نے کہا، \\'کیا آپ کے ماں باپ بھی پیزا ہیں؟\\' خاتون نے کہا، \\'ہاں، وہ بھی پیزا ہیں۔\\' پیزا نے کہا، \\'تو آپ کے ڈیڈی کا داڑھی کہاں ہے؟\\' خاتون نے کہا، \\'وہ میرے سر کے اوپر ہیں۔\\' پیزا نے کہا، \\'تو آپ کے باپ کا داڑھی کہاں ہے؟\\' خاتون نے کہا، \\'وہ میرے سر کے اوپر ہیں۔\\' پیزا نے کہا، \\'تو یہ آپ کی ماں باپ ہیں؟\\' خاتون نے کہا، \\'ہاں، یہ میں ہی ہوں۔\\'\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 43, 'total_tokens': 414, 'completion_time': 0.494079589, 'prompt_time': 0.030879016, 'queue_time': 0.129438743, 'total_time': 0.524958605}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b2de9c0-85d6-42f8-881a-4539bff92076-0', usage_metadata={'input_tokens': 43, 'output_tokens': 371, 'total_tokens': 414})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-8511-676b-8002-371af2ae002d'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-06T20:25:14.209047+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7cf8-617e-8001-051cb2c8452d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}, next=('joke_exp',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7cf8-617e-8001-051cb2c8452d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-06T20:25:13.359792+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7042-6fea-8000-03aeef0670aa'}}, tasks=(PregelTask(id='84a8ab59-da35-b15f-8f39-fcd939179d32', name='joke_exp', path=('__pregel_pull', 'joke_exp'), error=None, interrupts=(), state=None, result={'explain': AIMessage(content='Pizza کا یہ جوک ہے:\\n\\n\" Pizza ایک خاتون سے پوچھا گیا کہ وہ کیا ہے۔ وہ کہنے لگی کہ میں ایک پیزا ہوں۔ پیزا نے کہا، \\'کیا آپ کے ماں باپ بھی پیزا ہیں؟\\' خاتون نے کہا، \\'ہاں، وہ بھی پیزا ہیں۔\\' پیزا نے کہا، \\'تو آپ کے ڈیڈی کا داڑھی کہاں ہے؟\\' خاتون نے کہا، \\'وہ میرے سر کے اوپر ہیں۔\\' پیزا نے کہا، \\'تو آپ کے باپ کا داڑھی کہاں ہے؟\\' خاتون نے کہا، \\'وہ میرے سر کے اوپر ہیں۔\\' پیزا نے کہا، \\'تو یہ آپ کی ماں باپ ہیں؟\\' خاتون نے کہا، \\'ہاں، یہ میں ہی ہوں۔\\'\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 43, 'total_tokens': 414, 'completion_time': 0.494079589, 'prompt_time': 0.030879016, 'queue_time': 0.129438743, 'total_time': 0.524958605}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b2de9c0-85d6-42f8-881a-4539bff92076-0', usage_metadata={'input_tokens': 43, 'output_tokens': 371, 'total_tokens': 414})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke_gen',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7042-6fea-8000-03aeef0670aa'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-06T20:25:12.027332+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7041-6bfd-bfff-fa05f68fecb5'}}, tasks=(PregelTask(id='52104c82-77f3-2dfc-214d-03bcf4bf9800', name='joke_gen', path=('__pregel_pull', 'joke_gen'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 46, 'total_tokens': 64, 'completion_time': 0.016073858, 'prompt_time': 0.015830292, 'queue_time': 0.089567698, 'total_time': 0.03190415}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--43176fa6-b304-4ef2-b70f-4ca627fbcf1e-0', usage_metadata={'input_tokens': 46, 'output_tokens': 18, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f08b5f9-7041-6bfd-bfff-fa05f68fecb5'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-06T20:25:12.026824+00:00', parent_config=None, tasks=(PregelTask(id='a8c8bcc9-e509-4827-3d02-920637aea71d', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chatbot.get_state_history(config={'configurable':{'thread_id':'1'}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e282da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
